---
title: "The beauty of persistent kernels"
datePublished: Tue Nov 04 2025 21:04:32 GMT+0000 (Coordinated Universal Time)
cuid: cmhl24l19000102jp61h0dz1k
slug: the-beauty-of-persistent-kernels
tags: dotnet, kernel, gpu, dotcompute, persistent-kernel

---

At some point you get tired of launching the same GPU kernel a few million times a day just to move a few bytes. RingKernels in DotCompute are the answer to that particular form of self-inflicted pain.

Persistent kernels flip the model: **launch once, keep the GPU hot, push messages through it like an actor system**. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

---

## From fire-and-forget to “stay a while”

The traditional model looks like this:

> Host → Launch Kernel → GPU runs → Kernel dies → repeat

Each launch costs you microseconds in driver overhead. For fine-grained work or streaming scenarios, that overhead dominates real work very quickly. RingKernels instead:

> Host → **Launch once** → GPU stays resident → Process messages continuously ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

Under the hood you get:

* **Persistent execution** – kernels sit in a loop on the GPU, waiting on queues.
    
* **Lock-free message passing** – ring buffers with atomics instead of locks.
    
* **Actor-style programming** – each kernel instance has a mailbox, state and behaviour. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    

In practice this means **1M–10M messages/sec on CUDA** and similar numbers on Metal/OpenCL, with CPU simulation mode for debugging and unit tests. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

---

## What a RingKernel actually is

Conceptually, you write something like:

```csharp
[RingKernel(
    Mode = RingKernelMode.Persistent,
    MessagingStrategy = MessagePassingStrategy.AtomicQueue,
    Domain = RingKernelDomain.General)]
public class MyServiceKernel
{
    private long _processed;

    public void ProcessMessage(MyRequest msg)
    {
        var result = Handle(msg);
        _processed++;
        SendResult(result);
    }
}
```

DotCompute takes this and turns it into a persistent GPU service that you can activate, send messages to and monitor across CUDA, Metal, OpenCL or CPU backends. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

The interesting part is not the attribute. It’s what you can do once the kernel never really “goes away”.

---

## Use case 1: Graph analytics that never sleeps

Dynamic graphs (fraud networks, recommendation graphs, process graphs) don’t like batched, one-off kernels. They want **vertex-centric, message-driven** behaviour: vertices push messages to neighbours whenever something changes. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

RingKernels let you model each vertex (or a block of vertices) as a tiny GPU actor:

* The kernel keeps local state (rank, neighbours, counters).
    
* Incoming messages are rank contributions, updates, or structural changes.
    
* Outgoing messages propagate changes further in the graph.
    

You get:

* PageRank, connected components, label propagation, etc. running as **continuous services**, not “run job, write file, shut down”. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    
* Better behaviour on highly irregular graphs thanks to domain hints like `RingKernelDomain.GraphAnalytics` for load balancing and memory access optimizations. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    

Short version: graph algorithms start looking more like streaming systems than nightly batch jobs.

---

## Use case 2: Spatial simulations without halo drama

Stencil codes (CFD, heat diffusion, cellular automata) spend a lot of time exchanging halo data between neighbouring cells. With normal kernels you end up with:

1. Step kernel
    
2. Halo kernel
    
3. Synchronize
    
4. Repeat until someone complains about runtime
    

A RingKernel in `SpatialSimulation` mode keeps each cell (or tile) alive on the GPU: it receives halo messages, updates local state and pushes new halos back out. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

Benefits:

* **Local communication in shared memory** when possible.
    
* No repeated launch overhead for every timestep.
    
* Natural fit for adaptive meshes and regions that go quiet or hot over time.
    

If you’ve ever tried to bolt adaptivity on top of a rigid time-stepping CUDA loop, this is a welcome change.

---

## Use case 3: Real-time event processing on GPU

Persistent kernels are annoyingly good at **low-latency stream processing**:

* Sensor streams, tick data, telemetry, logs.
    
* Sliding windows, moving averages, anomaly detection. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    

An event-driven RingKernel keeps a small state machine per key (device, user, asset), updates statistics with every event and raises alerts when thresholds are breached. No kernel relaunch when the next event arrives; it’s already waiting.

`RingKernelMode.EventDriven` lets you trade a bit of activation overhead for better power usage on bursty workloads, which is handy on shared GPUs or laptops that insist on having batteries. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

---

## Use case 4: GPU-resident actor systems and services

DotCompute pushes the actor analogy quite far:

* Kernels behave as key-value stores, caches, or user sessions with mailboxes. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    
* You can compose them using **producer–consumer**, **request–reply**, **scatter–gather** and **pipeline** patterns directly on the GPU. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-advanced.html))
    

A few practical patterns from the docs:

* **GPU KV store** – a `KVStoreActor` kernel handling get/put/delete messages with in-kernel dictionaries and replies.
    
* **Scatter–gather workers** – a coordinator kernel partitions a large job, distributes fragments to worker kernels, then collects results and emits a combined response. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-advanced.html))
    
* **Streaming pipelines** – staged kernels (preprocess → transform → aggregate) connected via message passing, each stage independently scalable and monitored. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-advanced.html))
    

This is essentially an actor framework, except the actors are running inches away from your data in GPU memory.

---

## Use case 5: Long-lived state on GPU (without chaos)

Persistent kernels also unlock **stateful services** that live entirely on the device:

* Per-user or per-session state machines
    
* Rolling statistics and counters
    
* In-GPU caches (with eviction) ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-advanced.html))
    

Examples from the advanced guide:

* A kernel maintaining per-user analytics, periodic checkpoints and global statistics snapshots pushed back to the host.
    
* An LRU cache kernel with bounded state, eviction and reply messages for hits/misses. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-advanced.html))
    

You keep the hot path on the GPU, while still being able to snapshot and export state for durability or audit.

---

## Use case 6: Multi-kernel and multi-GPU orchestration

Once kernels are persistent, coordination starts to matter more than launches. RingKernels cover this too:

* **Coordinator kernels** that track registered workers, assign work, collect results and rebalance load. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-advanced.html))
    
* **Periodic tasks** inside kernels for health checks, heartbeats and dynamic scaling.
    

On top of that you get several **message passing strategies**:

* `SharedMemory` – ultra-low latency within a block.
    
* `AtomicQueue` – scalable global memory queues for distributed actors.
    
* `P2P` – direct GPU-to-GPU messaging for pipelines across devices.
    
* `NCCL` – collective operations (all-reduce, broadcast) across many GPUs or nodes. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    

That combination makes RingKernels viable for things like:

* Multi-GPU training loops with GPU-side coordination
    
* Cross-GPU graph analytics
    
* Service meshes where each “service” is a kernel running on whichever GPU has capacity this week
    

---

## Choosing modes and domains (without overthinking it)

The nice part is that DotCompute exposes the heavy tuning as **enum choices**:

* `Mode` – `Persistent` for long-running services, `EventDriven` for bursty loads or when you care about power. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    
* `MessagingStrategy` – local vs global vs multi-GPU trade-offs.
    
* `Domain` – hints like `GraphAnalytics`, `SpatialSimulation`, `ActorModel` to enable backend-specific optimizations. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))
    

Underneath there’s a lot of backend-specific work; on top you mostly decide what your workload looks like and let the runtime take it personally.

---

## Why this matters for .NET people

All of this is implemented as **plain C# classes with attributes**, running on top of CUDA, Metal, OpenCL or just the CPU if you feel like debugging on a train. The persistent-kernel pattern used to be a specialist CUDA trick; RingKernels turn it into something that fits into normal .NET application architecture. ([mivertowski.github.io](https://mivertowski.github.io/DotCompute/docs/articles/guides/ring-kernels-introduction.html))

You can:

* Prototype on CPU, deploy on GPU without rewriting the logic.
    
* Treat GPU kernels as first-class services in your system, not just math spells you cast once per batch.
    
* Keep latency low and throughput high without building a bespoke scheduling layer around every kernel.
    

---

## Closing

Persistent kernels are not magic. They’re just kernels that **refuse to leave the party**, paired with a messaging model that makes that stubbornness useful.

DotCompute’s RingKernels take that idea and push it across backends, domains and coordination patterns, so you can treat the GPU as a proper actor platform rather than a glorified for-loop accelerator.

If your workload looks anything like “a stream of small things, forever”, persistent kernels are probably the pretty solution you were trying very hard not to invent yourself.