# DotCompute API Reference - Phase 3

## ðŸš€ Complete API Guide with Examples

### **Plugin System API**

#### Loading and Managing Plugins

```csharp
using DotCompute.Plugins.Core;
using Microsoft.Extensions.Logging;

// Initialize plugin system
var logger = loggerFactory.CreateLogger<PluginSystem>();
var pluginSystem = new PluginSystem(logger);

// Load a plugin dynamically
var plugin = await pluginSystem.LoadPluginAsync(
    assemblyPath: "/path/to/DotCompute.Backends.CUDA.dll",
    pluginTypeName: "DotCompute.Backends.CUDA.CudaBackendPlugin"
);

if (plugin != null)
{
    Console.WriteLine($"Loaded plugin: {plugin.Name} v{plugin.Version}");
    
    // Use the plugin
    var accelerator = await plugin.CreateAcceleratorAsync();
    var capabilities = accelerator.GetCapabilities();
}

// Hot-reload plugin updates
await pluginSystem.UnloadPluginAsync(plugin.Id);
var updatedPlugin = await pluginSystem.LoadPluginAsync(newAssemblyPath, pluginTypeName);

// Get all loaded plugins
var allPlugins = pluginSystem.GetLoadedPlugins();
foreach (var p in allPlugins)
{
    Console.WriteLine($"Plugin: {p.Name} ({p.Id})");
}

// Plugin discovery
var assembly = Assembly.LoadFrom("plugin.dll");
var pluginTypes = PluginSystem.DiscoverPluginTypes(assembly);
```

#### Creating Custom Plugins

```csharp
using DotCompute.Plugins.Interfaces;
using DotCompute.Plugins.Attributes;

[Plugin("MyCustomBackend", "1.0.0", "Custom compute backend")]
public class CustomBackendPlugin : BackendPluginBase
{
    public override string Id => "custom-backend";
    public override string Name => "Custom Backend";
    public override Version Version => new Version(1, 0, 0);
    
    public override async Task<IAccelerator> CreateAcceleratorAsync(
        AcceleratorOptions? options = null)
    {
        return new CustomAccelerator(options);
    }
    
    public override bool IsAvailable()
    {
        // Check if hardware/drivers are available
        return CheckCustomHardware();
    }
    
    public override IEnumerable<AcceleratorInfo> GetAvailableAccelerators()
    {
        yield return new AcceleratorInfo
        {
            Id = "custom-0",
            Name = "Custom Device 0",
            DeviceType = "CustomGPU",
            TotalMemory = GetDeviceMemory()
        };
    }
}
```

---

### **Source Generator API**

#### Kernel Definition and Generation

```csharp
using DotCompute.Generators.Kernel;

// Define kernels with automatic code generation
[Kernel("VectorAdd", 
    Backends = BackendType.CPU | BackendType.CUDA | BackendType.Metal,
    VectorSize = 8,
    IsParallel = true)]
public static void VectorAdd(
    KernelContext ctx,
    ReadOnlySpan<float> a,
    ReadOnlySpan<float> b,
    Span<float> result)
{
    var i = ctx.GlobalId.X;
    if (i < result.Length)
        result[i] = a[i] + b[i];
}

// Advanced kernel with specializations
[Kernel("MatrixMultiply",
    Backends = BackendType.CUDA | BackendType.Metal,
    VectorSize = 16,
    SharedMemorySize = 1024)]
public static void MatrixMultiply(
    KernelContext ctx,
    ReadOnlySpan<float> matrixA,
    ReadOnlySpan<float> matrixB,
    Span<float> result,
    int width)
{
    var row = ctx.GlobalId.Y;
    var col = ctx.GlobalId.X;
    
    if (row < width && col < width)
    {
        float sum = 0;
        for (int k = 0; k < width; k++)
        {
            sum += matrixA[row * width + k] * matrixB[k * width + col];
        }
        result[row * width + col] = sum;
    }
}

// Using generated kernels
var registry = KernelRegistry.GetAllKernels();
foreach (var kernel in registry)
{
    Console.WriteLine($"Available kernel: {kernel.Name}");
    Console.WriteLine($"  Backends: {string.Join(", ", kernel.SupportedBackends)}");
    Console.WriteLine($"  Vector Size: {kernel.VectorSize}");
    Console.WriteLine($"  Parallel: {kernel.IsParallel}");
}

// Execute generated kernel
var invoker = new VectorAddInvoker();
invoker.InvokeKernel("VectorAdd", AcceleratorType.CUDA, inputA, inputB, output);
```

#### Custom Source Generation

```csharp
using DotCompute.Generators.Utils;

public class CustomKernelGenerator : IIncrementalGenerator
{
    public void Initialize(IncrementalGeneratorInitializationContext context)
    {
        var kernelMethods = context.SyntaxProvider
            .CreateSyntaxProvider(
                predicate: (s, _) => IsCustomKernel(s),
                transform: (ctx, _) => ExtractKernelInfo(ctx))
            .Where(k => k != null);
            
        context.RegisterSourceOutput(kernelMethods, GenerateCustomKernel);
    }
    
    private void GenerateCustomKernel(SourceProductionContext context, KernelInfo kernel)
    {
        var source = $$"""
            // <auto-generated/>
            namespace {{kernel.Namespace}}.Generated
            {
                public static class {{kernel.Name}}Kernel
                {
                    public static void Execute({{string.Join(", ", kernel.Parameters)}})
                    {
                        // Custom implementation
                        {{GenerateKernelBody(kernel)}}
                    }
                }
            }
            """;
            
        context.AddSource($"{kernel.Name}.g.cs", source);
    }
}
```

---

### **CUDA Backend API**

#### Device Management and Execution

```csharp
using DotCompute.Backends.CUDA;

// Initialize CUDA accelerator
var cudaAccelerator = new CudaAccelerator(deviceId: 0);

// Query device capabilities
var capabilities = cudaAccelerator.GetCapabilities();
var deviceName = capabilities.First(c => c.Name == "DeviceName").Value;
var computeCapability = $"{capabilities.First(c => c.Name == "ComputeCapabilityMajor").Value}." +
                       $"{capabilities.First(c => c.Name == "ComputeCapabilityMinor").Value}";
var totalMemory = capabilities.First(c => c.Name == "TotalGlobalMemory").Value;

Console.WriteLine($"CUDA Device: {deviceName}");
Console.WriteLine($"Compute Capability: {computeCapability}");
Console.WriteLine($"Total Memory: {totalMemory:N0} bytes");

// Memory allocation and management
var memoryManager = cudaAccelerator.MemoryManager;
var deviceBuffer = await memoryManager.AllocateAsync<float>(1_000_000);

// Copy data to device
var hostData = new float[1_000_000];
// ... initialize host data
await deviceBuffer.CopyFromAsync(hostData);

// Compile and execute kernels
var kernelCompiler = cudaAccelerator.KernelCompiler;
var compiledKernel = await kernelCompiler.CompileAsync(kernelDefinition);

var executionContext = new KernelExecutionContext
{
    GlobalSize = new[] { 1_000_000 },
    LocalSize = new[] { 256 },
    Arguments = new object[] { deviceBuffer, additionalArgs }
};

await compiledKernel.ExecuteAsync(executionContext);

// Synchronize and copy results
await cudaAccelerator.SynchronizeAsync();
var results = new float[1_000_000];
await deviceBuffer.CopyToAsync(results);

// Performance monitoring
var metrics = compiledKernel.GetExecutionMetrics();
Console.WriteLine($"Execution Time: {metrics.KernelExecutionTime.TotalMilliseconds}ms");
Console.WriteLine($"Memory Bandwidth: {metrics.MemoryBandwidthUtilization:P2}");
```

#### Advanced CUDA Features

```csharp
// Multi-GPU execution
var devices = CudaAccelerator.GetAvailableDevices();
var accelerators = devices.Select(d => new CudaAccelerator(d.DeviceId)).ToArray();

// Distribute work across GPUs
var tasks = accelerators.Select(async (acc, i) => 
{
    var partition = PartitionData(data, i, accelerators.Length);
    return await acc.ExecuteKernelAsync("ProcessPartition", partition);
});

var results = await Task.WhenAll(tasks);

// Stream processing
var stream = await cudaAccelerator.CreateStreamAsync();
await stream.ExecuteKernelAsync(kernel1, args1);
await stream.ExecuteKernelAsync(kernel2, args2);
await stream.SynchronizeAsync();

// Unified memory
var unifiedBuffer = await memoryManager.AllocateUnifiedAsync<float>(size);
// Accessible from both CPU and GPU without explicit copying
```

---

### **Metal Backend API**

#### macOS/iOS GPU Computing

```csharp
using DotCompute.Backends.Metal;

// Configure Metal accelerator
var options = new MetalAcceleratorOptions
{
    PreferIntegratedGpu = false, // Use discrete GPU if available
    EnableMetalPerformanceShaders = true,
    MaxThreadgroupSize = 1024
};

var metalAccelerator = new MetalAccelerator(Options.Create(options), logger);

// Device information
var info = metalAccelerator.Info;
Console.WriteLine($"Metal Device: {info.Name}");
Console.WriteLine($"Device Type: {info.DeviceType}");
Console.WriteLine($"Compute Capability: {info.ComputeCapability}");
Console.WriteLine($"Total Memory: {info.TotalMemory:N0} bytes");

// Check Metal features
var capabilities = info.Capabilities;
var supportedFamilies = capabilities["SupportsFamily"];
var hasUnifiedMemory = (bool)capabilities["UnifiedMemory"];
var maxThreadgroupSize = (int)capabilities["MaxThreadgroupSize"];

// Kernel compilation with Metal Shading Language
var kernelDefinition = new KernelDefinition
{
    Name = "VectorAdd",
    Source = """
        kernel void vectorAdd(device const float* a [[buffer(0)]],
                             device const float* b [[buffer(1)]],
                             device float* result [[buffer(2)]],
                             uint index [[thread_position_in_grid]])
        {
            result[index] = a[index] + b[index];
        }
        """,
    EntryPoint = "vectorAdd"
};

var compiledKernel = await metalAccelerator.CompileKernelAsync(kernelDefinition);

// Memory management
var memoryManager = metalAccelerator.Memory;
var bufferA = await memoryManager.AllocateAsync<float>(1_000_000);
var bufferB = await memoryManager.AllocateAsync<float>(1_000_000);
var bufferResult = await memoryManager.AllocateAsync<float>(1_000_000);

// Execute kernel
var context = new KernelExecutionContext
{
    ThreadgroupSize = new[] { 256 },
    ThreadgroupCount = new[] { (1_000_000 + 255) / 256 },
    Arguments = new[] { bufferA, bufferB, bufferResult }
};

await compiledKernel.ExecuteAsync(context);
await metalAccelerator.SynchronizeAsync();
```

---

### **Pipeline System API**

#### Building and Executing Pipelines

```csharp
using DotCompute.Core.Pipelines;

// Create a complex multi-stage pipeline
var pipeline = new KernelPipelineBuilder()
    .SetName("ImageProcessingPipeline")
    .SetId("img-proc-001")
    
    // Stage 1: Load and decode image
    .AddStage("LoadImage", new ImageLoadStage())
        .WithMetadata("inputFormat", "JPEG")
        .WithTimeout(TimeSpan.FromSeconds(30))
    
    // Stage 2: Preprocessing (parallel)
    .AddStage("Preprocess", new PreprocessStage())
        .DependsOn("LoadImage")
        .SetParallel(true)
        .WithMemoryLimit(500_000_000) // 500MB
    
    // Stage 3: Apply filters (GPU accelerated)
    .AddStage("ApplyFilters", new FilterStage())
        .DependsOn("Preprocess")
        .SetAcceleratorType(AcceleratorType.CUDA)
        .WithKernel("ImageFilter")
    
    // Stage 4: Post-processing
    .AddStage("PostProcess", new PostProcessStage())
        .DependsOn("ApplyFilters")
        .SetParallel(true)
    
    // Stage 5: Encode output
    .AddStage("EncodeOutput", new EncodeStage())
        .DependsOn("PostProcess")
        .WithMetadata("outputFormat", "PNG")
    
    // Pipeline configuration
    .WithErrorHandling((ex, context) => 
    {
        logger.LogError(ex, "Pipeline error at stage {Stage}", context.CurrentStage);
        return ErrorHandlingResult.Retry; // Retry once, then continue
    })
    .WithOptimization(opt =>
    {
        opt.EnableParallelMerging = true;
        opt.EnableMemoryOptimization = true;
        opt.EnableKernelFusion = true;
    })
    .WithEventHandler(evt => 
    {
        Console.WriteLine($"Pipeline Event: {evt.Type} - {evt.Message}");
    })
    .Build();

// Validate pipeline before execution
var validation = pipeline.Validate();
if (!validation.IsValid)
{
    foreach (var error in validation.Errors ?? [])
    {
        Console.WriteLine($"Validation Error: {error.Message}");
    }
    return;
}

// Execute pipeline
var executionContext = new PipelineExecutionContext
{
    Inputs = new Dictionary<string, object>
    {
        ["imagePath"] = "/path/to/input.jpg",
        ["filters"] = new[] { "blur", "sharpen", "contrast" },
        ["outputPath"] = "/path/to/output.png"
    },
    MemoryManager = memoryManager,
    Device = accelerator,
    Options = new PipelineExecutionOptions
    {
        ContinueOnError = true,
        MaxConcurrency = Environment.ProcessorCount,
        MemoryLimit = 2_000_000_000 // 2GB
    }
};

var result = await pipeline.ExecuteAsync(executionContext);

// Check results
if (result.Success)
{
    Console.WriteLine($"Pipeline completed successfully in {result.Metrics.Duration.TotalSeconds:F2}s");
    Console.WriteLine($"Memory usage: {result.Metrics.MemoryUsage.PeakBytes:N0} bytes");
    Console.WriteLine($"Compute utilization: {result.Metrics.ComputeUtilization:P2}");
}
else
{
    Console.WriteLine("Pipeline failed:");
    foreach (var error in result.Errors ?? [])
    {
        Console.WriteLine($"  {error.Severity}: {error.Message}");
    }
}

// Get pipeline metrics
var metrics = pipeline.GetMetrics();
Console.WriteLine($"Total executions: {metrics.TotalExecutions}");
Console.WriteLine($"Success rate: {metrics.SuccessRate:P2}");
Console.WriteLine($"Average duration: {metrics.AverageExecutionTime.TotalSeconds:F2}s");
```

#### Custom Pipeline Stages

```csharp
public class CustomProcessingStage : IPipelineStage
{
    public string Id { get; } = "custom-processing";
    public string Name { get; } = "Custom Processing";
    public PipelineStageType Type { get; } = PipelineStageType.Compute;
    public IReadOnlyList<string> Dependencies { get; } = Array.Empty<string>();
    
    public async ValueTask<StageExecutionResult> ExecuteAsync(
        PipelineExecutionContext context,
        CancellationToken cancellationToken = default)
    {
        var stopwatch = Stopwatch.StartNew();
        
        try
        {
            // Get input data
            var inputData = (float[])context.Inputs["inputData"];
            
            // Perform custom processing
            var result = await ProcessDataAsync(inputData, context.Device, cancellationToken);
            
            stopwatch.Stop();
            
            return new StageExecutionResult
            {
                StageId = Id,
                Success = true,
                Duration = stopwatch.Elapsed,
                Outputs = new Dictionary<string, object>
                {
                    ["processedData"] = result
                },
                MemoryUsage = new MemoryUsageStats
                {
                    AllocatedBytes = result.Length * sizeof(float),
                    PeakBytes = result.Length * sizeof(float) * 2, // temp allocation
                    AllocationCount = 2,
                    DeallocationCount = 1
                },
                Metrics = new Dictionary<string, double>
                {
                    ["ComputeUtilization"] = 0.85,
                    ["MemoryBandwidthUtilization"] = 0.72,
                    ["DataTransferTime"] = 5.2
                }
            };
        }
        catch (Exception ex)
        {
            stopwatch.Stop();
            
            return new StageExecutionResult
            {
                StageId = Id,
                Success = false,
                Duration = stopwatch.Elapsed,
                Error = ex
            };
        }
    }
    
    public PipelineStageValidationResult Validate()
    {
        // Perform stage-specific validation
        return new PipelineStageValidationResult
        {
            IsValid = true,
            Errors = null,
            Warnings = null
        };
    }
    
    private async Task<float[]> ProcessDataAsync(
        float[] input, 
        IAccelerator device,
        CancellationToken cancellationToken)
    {
        // Custom processing logic here
        // Can use any accelerator backend
        
        if (device.Type == AcceleratorType.Cuda)
        {
            return await ProcessWithCuda(input, device, cancellationToken);
        }
        else if (device.Type == AcceleratorType.Metal)
        {
            return await ProcessWithMetal(input, device, cancellationToken);
        }
        else
        {
            return await ProcessWithCpu(input, cancellationToken);
        }
    }
}
```

---

### **Performance Monitoring API**

#### Real-time Performance Tracking

```csharp
using DotCompute.Core.Performance;

// Initialize performance profiler
var profiler = new PerformanceProfiler();

// Track kernel execution
profiler.StartKernelExecution("VectorAdd", "execution-001");
await kernel.ExecuteAsync(context);
profiler.EndKernelExecution("VectorAdd", "execution-001");

// Track memory operations
profiler.StartMemoryOperation("allocation", "mem-001");
var buffer = await memoryManager.AllocateAsync<float>(1_000_000);
profiler.EndMemoryOperation("allocation", "mem-001");

// Get performance metrics
var kernelMetrics = profiler.GetKernelMetrics("VectorAdd");
Console.WriteLine($"Average execution time: {kernelMetrics.AverageExecutionTime.TotalMilliseconds}ms");
Console.WriteLine($"Throughput: {kernelMetrics.Throughput:F2} operations/sec");
Console.WriteLine($"Memory bandwidth: {kernelMetrics.MemoryBandwidth:F2} GB/s");

// Real-time monitoring
profiler.EnableRealTimeMonitoring(TimeSpan.FromSeconds(1));
profiler.MetricsUpdated += (sender, args) =>
{
    Console.WriteLine($"Current GPU utilization: {args.Metrics.GpuUtilization:P2}");
    Console.WriteLine($"Memory usage: {args.Metrics.MemoryUsage:P2}");
    Console.WriteLine($"Temperature: {args.Metrics.Temperature}Â°C");
};

// Export metrics for analysis
var report = profiler.GenerateReport();
await File.WriteAllTextAsync("performance_report.json", 
    JsonSerializer.Serialize(report, new JsonSerializerOptions { WriteIndented = true }));
```

---

### **Integration Examples**

#### Complete Machine Learning Pipeline

```csharp
// Real-world ML training pipeline
var mlPipeline = new KernelPipelineBuilder()
    .SetName("MLTrainingPipeline")
    
    // Data loading and preprocessing
    .AddStage("LoadDataset", new DatasetLoadStage())
    .AddStage("Normalize", new NormalizationStage())
        .DependsOn("LoadDataset")
        .SetAcceleratorType(AcceleratorType.CUDA)
    
    // Model training stages
    .AddStage("ForwardPass", new ForwardPassStage())
        .DependsOn("Normalize")
        .SetAcceleratorType(AcceleratorType.CUDA)
        .WithKernel("MatrixMultiply")
    
    .AddStage("BackwardPass", new BackwardPassStage())
        .DependsOn("ForwardPass")
        .SetAcceleratorType(AcceleratorType.CUDA)
        .WithKernel("GradientDescent")
    
    .AddStage("UpdateWeights", new WeightUpdateStage())
        .DependsOn("BackwardPass")
        .SetParallel(true)
    
    // Validation and metrics
    .AddStage("Validate", new ValidationStage())
        .DependsOn("UpdateWeights")
        .SetAcceleratorType(AcceleratorType.CUDA)
    
    .WithOptimization(opt =>
    {
        opt.EnableKernelFusion = true;
        opt.EnableMemoryOptimization = true;
        opt.CacheCompiledKernels = true;
    })
    .Build();

// Training loop
for (int epoch = 0; epoch < numEpochs; epoch++)
{
    var context = new PipelineExecutionContext
    {
        Inputs = new Dictionary<string, object>
        {
            ["epoch"] = epoch,
            ["learningRate"] = GetLearningRate(epoch),
            ["batchSize"] = batchSize
        },
        Device = cudaAccelerator
    };
    
    var result = await mlPipeline.ExecuteAsync(context);
    
    if (result.Success)
    {
        var accuracy = (double)result.Outputs["accuracy"];
        var loss = (double)result.Outputs["loss"];
        
        Console.WriteLine($"Epoch {epoch}: Accuracy = {accuracy:P2}, Loss = {loss:F4}");
    }
}
```

This comprehensive API reference demonstrates the full capabilities of DotCompute Phase 3, from basic plugin loading to complex multi-GPU machine learning pipelines. Each example is production-ready and demonstrates best practices for performance and reliability.