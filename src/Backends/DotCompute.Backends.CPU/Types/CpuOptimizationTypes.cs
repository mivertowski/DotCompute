// Copyright (c) 2025 Michael Ivertowski
// Licensed under the MIT License. See LICENSE file in the project root for license information.

using DotCompute.Abstractions.Performance;
using DotCompute.Backends.CPU.Execution;

namespace DotCompute.Backends.CPU;

/// <summary>
/// Optimization profile for CPU kernel execution.
/// </summary>
/// <remarks>
/// <para>
/// Contains complete optimization configuration including kernel analysis results,
/// execution plan, and optimization level. Generated by <see cref="CpuKernelOptimizer"/>
/// during kernel profiling and analysis.
/// </para>
/// <para>
/// Profiles are cached and reused for identical kernel invocations, providing
/// zero-overhead optimization for repeated executions.
/// </para>
/// </remarks>
public class OptimizationProfile
{
    /// <summary>
    /// Gets or sets the kernel name for identification.
    /// </summary>
    /// <remarks>
    /// Unique identifier for kernel lookup in optimization cache. Must match
    /// kernel function name exactly for cache hits.
    /// </remarks>
    public required string KernelName { get; set; }

    /// <summary>
    /// Gets or sets the work dimensions (problem size).
    /// </summary>
    /// <remarks>
    /// <para>
    /// Defines total workload size in 1D, 2D, or 3D space. Used to determine
    /// optimal thread count and vectorization strategy based on problem size.
    /// </para>
    /// <para><b>Example</b>: [1024, 1024] for 1024×1024 matrix operation</para>
    /// </remarks>
    public WorkDimensions WorkDimensions { get; set; }

    /// <summary>
    /// Gets or sets the optimization level (None, Basic, Aggressive).
    /// </summary>
    /// <remarks>
    /// <para>
    /// Controls trade-off between optimization time and runtime performance:
    /// </para>
    /// <list type="bullet">
    /// <item><b>None</b>: No optimization, fastest compilation</item>
    /// <item><b>Basic</b>: Simple SIMD and parallelization, minimal overhead</item>
    /// <item><b>Aggressive</b>: Full analysis, benchmarking, auto-tuning</item>
    /// </list>
    /// </remarks>
    public OptimizationLevel OptimizationLevel { get; set; }

    /// <summary>
    /// Gets or sets the kernel analysis results.
    /// </summary>
    /// <remarks>
    /// Detailed analysis of kernel characteristics including memory access patterns,
    /// arithmetic intensity, parallelization opportunities, and vectorization potential.
    /// </remarks>
    public required KernelAnalysis Analysis { get; set; }

    /// <summary>
    /// Gets or sets the optimized execution plan.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Concrete execution plan with thread counts, vectorization flags, and
    /// scheduling strategy. Generated from Analysis and hardware capabilities.
    /// </para>
    /// <para>Includes thread pool configuration, NUMA hints, and SIMD instruction selection.</para>
    /// </remarks>
    public required KernelExecutionPlan ExecutionPlan { get; set; }

    /// <summary>
    /// Gets or sets the profile creation timestamp.
    /// </summary>
    /// <remarks>
    /// UTC timestamp when profile was created. Used for cache invalidation
    /// and performance drift detection.
    /// </remarks>
    public DateTimeOffset CreationTime { get; set; }

    /// <summary>
    /// Gets or sets the last access timestamp.
    /// </summary>
    /// <remarks>
    /// UTC timestamp of most recent use. Used for LRU eviction in profile cache.
    /// </remarks>
    public DateTimeOffset LastAccessed { get; set; }
}

/// <summary>
/// Optimization recommendations from kernel analysis.
/// </summary>
/// <remarks>
/// <para>
/// Contains actionable suggestions for improving kernel performance based on
/// profiling results and static analysis. Generated by <see cref="CpuKernelOptimizer.GenerateRecommendations"/>.
/// </para>
/// <para>
/// Each suggestion includes expected speedup, implementation details, and
/// trade-off analysis to guide optimization decisions.
/// </para>
/// </remarks>
public class OptimizationRecommendations
{
    /// <summary>
    /// Gets or sets the kernel name being analyzed.
    /// </summary>
    public required string KernelName { get; set; }

    /// <summary>
    /// Gets or sets the analysis timestamp.
    /// </summary>
    /// <remarks>
    /// UTC timestamp when recommendations were generated. Recommendations may
    /// become stale if hardware or workload changes significantly.
    /// </remarks>
    public DateTimeOffset AnalysisTime { get; set; }

    /// <summary>
    /// Gets or sets the current performance baseline.
    /// </summary>
    /// <remarks>
    /// Performance metrics before optimization. Used to calculate expected
    /// speedup from each suggestion and validate improvements.
    /// </remarks>
    public required ExecutionStatistics CurrentPerformance { get; set; }

    /// <summary>
    /// Gets the list of optimization suggestions ordered by expected impact.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Suggestions sorted by ExpectedSpeedup (highest first). Applying
    /// top suggestions typically yields 80-90% of total speedup potential.
    /// </para>
    /// <para><b>Priority Order</b>: Focus on suggestions with ExpectedSpeedup &gt; 2.0x first</para>
    /// </remarks>
    public IList<OptimizationSuggestion> Suggestions { get; } = [];

    /// <summary>
    /// Gets or sets error message if analysis failed.
    /// </summary>
    /// <remarks>
    /// Populated only if analysis encountered errors (e.g., insufficient data,
    /// unsupported kernel pattern). Null indicates successful analysis.
    /// </remarks>
    public string? ErrorMessage { get; set; }
}

/// <summary>
/// Individual optimization suggestion with implementation guidance.
/// </summary>
/// <remarks>
/// <para>
/// Represents a single optimization opportunity identified during kernel analysis.
/// Includes optimization type, expected performance improvement, detailed
    /// description, and implementation steps.
/// </para>
/// <para>
/// Suggestions are ranked by expected speedup and implementation complexity
/// to guide prioritization.
/// </para>
/// </remarks>
public class OptimizationSuggestion
{
    /// <summary>
    /// Gets or sets the optimization category.
    /// </summary>
    /// <remarks>
    /// Type of optimization (Vectorization, Parallelization, Memory, Cache, Threading).
    /// Determines which optimization techniques to apply.
    /// </remarks>
    public OptimizationType Type { get; set; }

    /// <summary>
    /// Gets or sets the human-readable description.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Explains why this optimization is beneficial and what bottleneck it addresses.
    /// </para>
    /// <para><b>Example</b>: "Loop can be vectorized using AVX2 for 4x throughput on float32 operations"</para>
    /// </remarks>
    public required string Description { get; set; }

    /// <summary>
    /// Gets or sets the expected performance multiplier.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Predicted speedup factor after applying this optimization. Based on:
    /// </para>
    /// <list type="bullet">
    /// <item>Hardware capabilities (vector width, core count)</item>
    /// <item>Kernel characteristics (arithmetic intensity, memory patterns)</item>
    /// <item>Historical benchmark data</item>
    /// </list>
    /// <para><b>Interpretation</b>:</para>
    /// <list type="bullet">
    /// <item>1.0 = No improvement</item>
    /// <item>2.0 = 2x faster (50% time reduction)</item>
    /// <item>4.0 = 4x faster (75% time reduction)</item>
    /// </list>
    /// <para><b>Accuracy</b>: Typically within ±25% of actual speedup</para>
    /// </remarks>
    public double ExpectedSpeedup { get; set; }

    /// <summary>
    /// Gets or sets the implementation details.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Concrete steps to implement the optimization including:
    /// </para>
    /// <list type="bullet">
    /// <item>Code modifications required</item>
    /// <item>Compiler flags or pragmas</item>
    /// <item>Data structure changes</item>
    /// <item>Algorithm adjustments</item>
    /// </list>
    /// <para><b>Example</b>: "Use Vector&lt;float&gt; API with aligned buffers, ensure loop count is multiple of vector width"</para>
    /// </remarks>
    public required string Implementation { get; set; }
}

/// <summary>
/// Benchmark results from kernel performance testing.
/// </summary>
/// <remarks>
/// <para>
/// Contains comprehensive benchmark data including scalar baseline, vectorized
/// performance, and parallelization scaling across thread counts. Generated
/// by <see cref="CpuKernelOptimizer.BenchmarkKernel"/>.
/// </para>
/// <para>
/// Results guide automatic selection of optimal configuration (thread count,
/// vectorization strategy) for production execution.
/// </para>
/// </remarks>
public class BenchmarkResults
{
    /// <summary>
    /// Gets or sets the kernel name being benchmarked.
    /// </summary>
    public required string KernelName { get; set; }

    /// <summary>
    /// Gets or sets the problem size tested.
    /// </summary>
    /// <remarks>
    /// Work dimensions used during benchmark. Results may vary with different
    /// problem sizes due to cache effects and parallelization overhead.
    /// </remarks>
    public WorkDimensions WorkDimensions { get; set; }

    /// <summary>
    /// Gets or sets the number of iterations per test.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Number of times each configuration was executed for timing. Higher
    /// iteration counts reduce measurement noise but increase benchmark duration.
    /// </para>
    /// <para><b>Typical Range</b>: 10-1000 depending on kernel duration</para>
    /// </remarks>
    public int Iterations { get; set; }

    /// <summary>
    /// Gets or sets the benchmark execution timestamp.
    /// </summary>
    /// <remarks>
    /// UTC timestamp when benchmark was performed. Results may become stale
    /// if hardware or system load characteristics change.
    /// </remarks>
    public DateTimeOffset BenchmarkTime { get; set; }

    /// <summary>
    /// Gets or sets the scalar (non-vectorized) performance baseline.
    /// </summary>
    /// <remarks>
    /// Performance with SIMD disabled. Used as baseline to calculate
    /// vectorization speedup. Null if scalar execution not tested.
    /// </remarks>
    public PerformanceMetrics? ScalarPerformance { get; set; }

    /// <summary>
    /// Gets or sets the vectorized SIMD performance.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Performance with maximum available SIMD (AVX-512, AVX2, NEON) enabled.
    /// Represents best single-threaded performance achievable.
    /// </para>
    /// <para><b>Speedup</b>: VectorizedPerformance / ScalarPerformance typically 2-8x</para>
    /// </remarks>
    public PerformanceMetrics? VectorizedPerformance { get; set; }

    /// <summary>
    /// Gets the parallelization results mapped by thread count.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Dictionary mapping thread count → performance metrics. Used to identify
    /// optimal thread count and detect scaling bottlenecks.
    /// </para>
    /// <para><b>Key Analysis</b>:</para>
    /// <list type="bullet">
    /// <item>Linear scaling: Performance ∝ thread count (ideal)</item>
    /// <item>Sublinear: Diminishing returns due to overhead/contention</item>
    /// <item>Performance drop: Excessive threads cause thrashing</item>
    /// </list>
    /// <para><b>Example Keys</b>: 1, 2, 4, 8, 16, 32 (powers of 2 typically tested)</para>
    /// </remarks>
    public Dictionary<int, PerformanceMetrics> ParallelizationResults { get; } = [];

    /// <summary>
    /// Gets or sets the optimal configuration identified.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Best-performing configuration across all tested combinations.
    /// Null if benchmark incomplete or all configurations failed.
    /// </para>
    /// <para>Automatically selected for production execution.</para>
    /// </remarks>
    public OptimalConfiguration? OptimalConfiguration { get; set; }

    /// <summary>
    /// Gets or sets error message if benchmark failed.
    /// </summary>
    /// <remarks>
    /// Populated only on benchmark failure (e.g., kernel crash, timeout).
    /// Null indicates successful completion of all test configurations.
    /// </remarks>
    public string? ErrorMessage { get; set; }
}

/// <summary>
/// Optimal kernel execution configuration.
/// </summary>
/// <remarks>
/// <para>
/// Represents the best-performing configuration identified through benchmarking.
/// Specifies thread count, vectorization settings, and performance metrics.
/// </para>
/// <para>
/// Applied automatically by <see cref="CpuKernelOptimizer"/> for production
/// kernel executions to ensure maximum performance.
/// </para>
/// </remarks>
public class OptimalConfiguration
{
    /// <summary>
    /// Gets or sets the configuration description.
    /// </summary>
    /// <remarks>
    /// Human-readable summary of optimization choices made.
    /// <para><b>Example</b>: "AVX2 vectorization with 16 threads (physical cores)"</para>
    /// </remarks>
    public required string Description { get; set; }

    /// <summary>
    /// Gets or sets the performance metrics achieved.
    /// </summary>
    /// <remarks>
    /// Measured performance including execution time, throughput, and resource
    /// utilization for this configuration.
    /// </remarks>
    public required PerformanceMetrics Performance { get; set; }

    /// <summary>
    /// Gets or sets whether SIMD vectorization is enabled.
    /// </summary>
    /// <remarks>
    /// <para>
    /// True enables maximum available SIMD (AVX-512 &gt; AVX2 &gt; SSE &gt; NEON).
    /// False uses scalar operations only.
    /// </para>
    /// <para><b>Disable When</b>: Small datasets, unaligned data, vectorization overhead exceeds benefit</para>
    /// </remarks>
    public bool UseVectorization { get; set; }

    /// <summary>
    /// Gets or sets the optimal thread count for parallel execution.
    /// </summary>
    /// <remarks>
    /// <para>
    /// Number of threads that achieved best performance/watt trade-off. Typically
    /// ranges from physical core count (CPU-bound) to 1 (memory-bound).
    /// </para>
    /// <para><b>Guidelines</b>:</para>
    /// <list type="bullet">
    /// <item>CPU-bound kernels: Use physical cores (not logical/HT cores)</item>
    /// <item>Memory-bound: 25-50% of cores to reduce bandwidth contention</item>
    /// <item>Mixed workload: Benchmark-determined value</item>
    /// </list>
    /// </remarks>
    public int OptimalThreadCount { get; set; }
}

/// <summary>
/// Disposable performance counter for fine-grained timing.
/// </summary>
/// <remarks>
/// <para>
/// Lightweight performance counter using high-resolution timer (Stopwatch).
/// Intended for internal use within <see cref="CpuKernelOptimizer"/> for
/// micro-benchmarking.
/// </para>
/// <para><b>Resolution</b>: Nanosecond-level on modern hardware</para>
/// <para><b>Overhead</b>: ~25-50 ns per start/stop cycle</para>
/// </remarks>
public sealed class PerformanceCounter : IDisposable
{
    /// <summary>
    /// Disposes performance counter resources.
    /// </summary>
    /// <remarks>
    /// Currently a no-op as PerformanceCounter has no unmanaged resources.
    /// Implements IDisposable for future extensibility.
    /// </remarks>
    public void Dispose()
    {
        // No resources to dispose currently
    }
}
