using System;
using System.Collections.Generic;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using System.Threading;
using System.Threading.Tasks;
using DotCompute.Abstractions;
using DotCompute.Linq.Compilation;
using DotCompute.Backends.CUDA.Native;
using Microsoft.Extensions.Logging;

namespace DotCompute.Backends.CUDA.Compilation;

/// <summary>
/// Helper class for CUDA runtime checks used during compilation.
/// </summary>
internal static class CudaRuntimeHelper
{
    /// <summary>
    /// Checks if CUDA driver is available.
    /// </summary>
    public static bool IsCudaAvailable()
    {
        try
        {
            // Try to get device count as a simple availability check
            CudaRuntime.cudaGetDeviceCount(out int count);
            return count > 0;
        }
        catch (DllNotFoundException)
        {
            return false;
        }
        catch (EntryPointNotFoundException)
        {
            return false;
        }
        catch
        {
            return false;
        }
    }

    /// <summary>
    /// Gets the number of CUDA devices.
    /// </summary>
    public static int GetDeviceCount()
    {
        try
        {
            CudaRuntime.cudaGetDeviceCount(out int count);
            return count;
        }
        catch
        {
            return 0;
        }
    }

    /// <summary>
    /// Gets the CUDA driver version.
    /// </summary>
    public static string GetDriverVersion()
    {
        try
        {
            var version = CudaRuntime.GetDriverVersion();
            return version.ToString();
        }
        catch
        {
            return "Unknown";
        }
    }
}

/// <summary>
/// Compiles CUDA kernels at runtime using NVRTC (NVIDIA Runtime Compilation).
/// </summary>
/// <remarks>
/// This compiler:
/// 1. Takes CUDA C source code generated by CudaKernelGenerator
/// 2. Compiles it to PTX (portable) or CUBIN (binary) using NVRTC
/// 3. Loads the compiled module into the CUDA driver
/// 4. Returns a CompiledKernel ready for execution
///
/// NVRTC provides runtime compilation with these benefits:
/// - No need for nvcc at deployment time
/// - Compile for exact GPU compute capability at runtime
/// - Optimize for specific hardware characteristics
/// - Support for dynamic kernel generation
/// </remarks>
public sealed class CudaRuntimeKernelCompiler : IGpuKernelCompiler
{
    private readonly ILogger<CudaRuntimeKernelCompiler> _logger;
    private readonly string _cudaIncludePath;

    /// <summary>
    /// Initializes a new CUDA runtime kernel compiler.
    /// </summary>
    public CudaRuntimeKernelCompiler(ILogger<CudaRuntimeKernelCompiler> logger)
    {
        _logger = logger ?? throw new ArgumentNullException(nameof(logger));

        // Try to detect CUDA include path
        _cudaIncludePath = DetectCudaIncludePath();
    }

    /// <inheritdoc />
    public ComputeBackend TargetBackend => ComputeBackend.Cuda;

    /// <inheritdoc />
    public bool IsAvailable()
    {
        if (!NvrtcNative.IsAvailable())
        {
            _logger.LogWarning("NVRTC library not found - CUDA runtime compilation unavailable");
            return false;
        }

        // Check CUDA driver availability
        if (!CudaRuntimeHelper.IsCudaAvailable())
        {
            _logger.LogWarning("CUDA driver not found - runtime compilation unavailable");
            return false;
        }

        return true;
    }

    /// <inheritdoc />
    public string GetDiagnostics()
    {
        var sb = new StringBuilder();
        sb.AppendLine("CUDA Kernel Compiler Diagnostics:");
        sb.AppendLine($"  NVRTC Version: {NvrtcNative.GetVersion()}");
        sb.AppendLine($"  NVRTC Available: {NvrtcNative.IsAvailable()}");
        sb.AppendLine($"  CUDA Driver Available: {CudaRuntimeHelper.IsCudaAvailable()}");
        sb.AppendLine($"  CUDA Include Path: {_cudaIncludePath}");

        if (CudaRuntimeHelper.IsCudaAvailable())
        {
            sb.AppendLine($"  Driver Version: {CudaRuntimeHelper.GetDriverVersion()}");
            sb.AppendLine($"  Device Count: {CudaRuntimeHelper.GetDeviceCount()}");
        }

        return sb.ToString();
    }

    /// <inheritdoc />
    public async Task<CompiledKernel?> CompileAsync(
        string sourceCode,
        TypeMetadata metadata,
        CompilationOptions options,
        CancellationToken cancellationToken = default)
    {
        if (string.IsNullOrWhiteSpace(sourceCode))
            throw new ArgumentNullException(nameof(sourceCode));
        if (metadata == null)
            throw new ArgumentNullException(nameof(metadata));
        if (options == null)
            throw new ArgumentNullException(nameof(options));

        if (!IsAvailable())
        {
            _logger.LogWarning("CUDA compilation unavailable - NVRTC or CUDA driver not found");
            return null;
        }

        // Run compilation on thread pool to avoid blocking
        return await Task.Run(() => CompileInternal(sourceCode, metadata, options, cancellationToken), cancellationToken);
    }

    /// <summary>
    /// Internal compilation implementation (runs on thread pool).
    /// </summary>
    private CompiledKernel? CompileInternal(
        string sourceCode,
        TypeMetadata metadata,
        CompilationOptions options,
        CancellationToken cancellationToken)
    {
        IntPtr program = IntPtr.Zero;
        try
        {
            // Step 1: Create NVRTC program
            string programName = $"kernel_{metadata.InputType?.Name ?? "unknown"}_{Guid.NewGuid():N}.cu";
            var result = NvrtcNative.nvrtcCreateProgram(
                out program,
                sourceCode,
                programName,
                0, // No headers for now
                null,
                null);

            if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
            {
                _logger.LogError("Failed to create NVRTC program: {Error}", NvrtcNative.GetErrorString(result));
                return null;
            }

            // Step 2: Build compilation options
            var compilerOptions = BuildCompilerOptions(options);
            _logger.LogDebug("NVRTC compilation options: {Options}", string.Join(" ", compilerOptions));

            // Step 3: Compile the program
            cancellationToken.ThrowIfCancellationRequested();
            result = NvrtcNative.nvrtcCompileProgram(program, compilerOptions.Count, compilerOptions.ToArray());

            // Step 4: Get compilation log (even if compilation succeeded, may have warnings)
            string compilationLog = GetCompilationLog(program);
            if (!string.IsNullOrWhiteSpace(compilationLog))
            {
                if (result == NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
                {
                    _logger.LogDebug("NVRTC compilation log:\n{Log}", compilationLog);
                }
                else
                {
                    _logger.LogError("NVRTC compilation failed:\n{Log}", compilationLog);
                }
            }

            if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
            {
                _logger.LogError("NVRTC compilation failed with error: {Error}", NvrtcNative.GetErrorString(result));
                return null;
            }

            // Step 5: Get compiled output (PTX or CUBIN)
            cancellationToken.ThrowIfCancellationRequested();
            byte[] compiledCode = options.GeneratePTX ? GetPTX(program) : GetCUBIN(program);
            if (compiledCode.Length == 0)
            {
                _logger.LogError("Failed to retrieve compiled code from NVRTC");
                return null;
            }

            _logger.LogInformation("NVRTC compilation successful: {Size} bytes ({Format})",
                compiledCode.Length, options.GeneratePTX ? "PTX" : "CUBIN");

            // Step 6: Load module into CUDA driver
            cancellationToken.ThrowIfCancellationRequested();
            var (moduleHandle, kernelHandle) = LoadModule(compiledCode, options.GeneratePTX);
            if (moduleHandle == IntPtr.Zero || kernelHandle == IntPtr.Zero)
            {
                _logger.LogError("Failed to load compiled module into CUDA driver");
                return null;
            }

            // Step 7: Calculate recommended grid dimensions
            int dataSize = 1024; // Default, will be overridden by executor based on actual data
            var gridDimensions = GridDimensions.CreateOptimized(dataSize);

            return new CompiledKernel
            {
                Backend = ComputeBackend.Cuda,
                KernelHandle = kernelHandle,
                ModuleHandle = moduleHandle,
                Metadata = metadata,
                RecommendedGrid = gridDimensions,
                EntryPoint = "kernel_main" // Standard entry point from CudaKernelGenerator
            };
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Unexpected error during CUDA kernel compilation");
            return null;
        }
        finally
        {
            // Clean up NVRTC program
            if (program != IntPtr.Zero)
            {
                NvrtcNative.nvrtcDestroyProgram(ref program);
            }
        }
    }

    /// <summary>
    /// Builds compiler options array for NVRTC.
    /// </summary>
    private List<string> BuildCompilerOptions(CompilationOptions options)
    {
        var opts = new List<string>();

        // Compute capability target
        string arch = options.TargetArchitecture ?? GetDefaultComputeCapability();
        if (!arch.StartsWith("sm_"))
            arch = $"sm_{arch.Replace(".", "")}";
        opts.Add($"--gpu-architecture={arch}");

        // Optimization level
        int optLevel = options.OptimizationLevel switch
        {
            OptimizationLevel.None => 0,
            OptimizationLevel.Conservative => 1,
            OptimizationLevel.Balanced => 2,
            OptimizationLevel.Aggressive => 3,
            OptimizationLevel.MLOptimized => 3,
            _ => 2
        };
        opts.Add($"-O{optLevel}");

        // Debug information
        if (options.GenerateDebugInfo)
        {
            opts.Add("--device-debug");
            opts.Add("--generate-line-info");
        }
        else if (options.GenerateLineInfo)
        {
            opts.Add("--generate-line-info");
        }

        // Fast math
        if (options.UseFastMath)
        {
            opts.Add("--use_fast_math");
        }

        // Register limit
        if (options.MaxRegistersPerThread.HasValue)
        {
            opts.Add($"--maxrregcount={options.MaxRegistersPerThread.Value}");
        }

        // Include paths
        if (!string.IsNullOrEmpty(_cudaIncludePath))
        {
            opts.Add($"-I{_cudaIncludePath}");
        }

        foreach (var includePath in options.IncludePaths)
        {
            opts.Add($"-I{includePath}");
        }

        // Preprocessor defines
        foreach (var (key, value) in options.Defines)
        {
            opts.Add($"-D{key}={value}");
        }

        // Additional flags
        opts.AddRange(options.AdditionalFlags);

        // Standard includes and settings
        opts.Add("--std=c++17"); // Modern C++ standard
        opts.Add("--extra-device-vectorization"); // Enable vectorization

        return opts;
    }

    /// <summary>
    /// Gets the compilation log from NVRTC program.
    /// </summary>
    private string GetCompilationLog(IntPtr program)
    {
        // Get log size
        var result = NvrtcNative.nvrtcGetProgramLogSize(program, out IntPtr logSize);
        if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS || logSize.ToInt64() <= 1)
            return string.Empty;

        // Allocate buffer and get log
        IntPtr logBuffer = Marshal.AllocHGlobal(logSize);
        try
        {
            result = NvrtcNative.nvrtcGetProgramLog(program, logBuffer);
            if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
                return string.Empty;

            return Marshal.PtrToStringAnsi(logBuffer) ?? string.Empty;
        }
        finally
        {
            Marshal.FreeHGlobal(logBuffer);
        }
    }

    /// <summary>
    /// Gets PTX output from compiled program.
    /// </summary>
    private byte[] GetPTX(IntPtr program)
    {
        // Get PTX size
        var result = NvrtcNative.nvrtcGetPTXSize(program, out IntPtr ptxSize);
        if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
            return Array.Empty<byte>();

        // Allocate buffer and get PTX
        IntPtr ptxBuffer = Marshal.AllocHGlobal(ptxSize);
        try
        {
            result = NvrtcNative.nvrtcGetPTX(program, ptxBuffer);
            if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
                return Array.Empty<byte>();

            // Copy to managed array
            byte[] ptx = new byte[ptxSize.ToInt32()];
            Marshal.Copy(ptxBuffer, ptx, 0, ptx.Length);
            return ptx;
        }
        finally
        {
            Marshal.FreeHGlobal(ptxBuffer);
        }
    }

    /// <summary>
    /// Gets CUBIN output from compiled program.
    /// </summary>
    private byte[] GetCUBIN(IntPtr program)
    {
        // Get CUBIN size
        var result = NvrtcNative.nvrtcGetCUBINSize(program, out IntPtr cubinSize);
        if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
            return Array.Empty<byte>();

        // Allocate buffer and get CUBIN
        IntPtr cubinBuffer = Marshal.AllocHGlobal(cubinSize);
        try
        {
            result = NvrtcNative.nvrtcGetCUBIN(program, cubinBuffer);
            if (result != NvrtcNative.nvrtcResult.NVRTC_SUCCESS)
                return Array.Empty<byte>();

            // Copy to managed array
            byte[] cubin = new byte[cubinSize.ToInt32()];
            Marshal.Copy(cubinBuffer, cubin, 0, cubin.Length);
            return cubin;
        }
        finally
        {
            Marshal.FreeHGlobal(cubinBuffer);
        }
    }

    /// <summary>
    /// Loads compiled module and gets kernel function handle.
    /// </summary>
    private (IntPtr moduleHandle, IntPtr kernelHandle) LoadModule(byte[] compiledCode, bool isPTX)
    {
        IntPtr moduleHandle = IntPtr.Zero;
        IntPtr imagePtr = IntPtr.Zero;

        try
        {
            // Step 1: Copy compiled code to unmanaged memory
            imagePtr = Marshal.AllocHGlobal(compiledCode.Length);
            Marshal.Copy(compiledCode, 0, imagePtr, compiledCode.Length);

            // Step 2: Load module from PTX/CUBIN
            _logger.LogDebug("Loading CUDA module ({Size} bytes, {Format})", compiledCode.Length, isPTX ? "PTX" : "CUBIN");

            var result = CudaRuntime.cuModuleLoadDataEx(
                out moduleHandle,
                imagePtr,
                0,  // No options for now
                Array.Empty<IntPtr>(),
                Array.Empty<IntPtr>());

            if (result != CudaRuntime.CudaError.Success)
            {
                _logger.LogError("Failed to load CUDA module: {Error}", result);
                return (IntPtr.Zero, IntPtr.Zero);
            }

            _logger.LogDebug("CUDA module loaded successfully: 0x{Module:X}", moduleHandle.ToInt64());

            // Step 3: Get kernel function handle
            // Standard entry point name from CudaKernelGenerator
            string entryPoint = "kernel_main";

            result = CudaRuntime.cuModuleGetFunction(
                out IntPtr kernelHandle,
                moduleHandle,
                entryPoint);

            if (result != CudaRuntime.CudaError.Success)
            {
                _logger.LogError("Failed to get kernel function '{EntryPoint}': {Error}", entryPoint, result);

                // Try to unload the module since we can't use it
                CudaRuntime.cuModuleUnload(moduleHandle);
                return (IntPtr.Zero, IntPtr.Zero);
            }

            _logger.LogInformation("Kernel function '{EntryPoint}' loaded successfully: 0x{Kernel:X}",
                entryPoint, kernelHandle.ToInt64());

            return (moduleHandle, kernelHandle);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Exception during CUDA module loading");

            // Clean up module if it was loaded
            if (moduleHandle != IntPtr.Zero)
            {
                try
                {
                    CudaRuntime.cuModuleUnload(moduleHandle);
                }
                catch (Exception cleanupEx)
                {
                    _logger.LogWarning(cleanupEx, "Failed to unload module during error cleanup");
                }
            }

            return (IntPtr.Zero, IntPtr.Zero);
        }
        finally
        {
            // Always free unmanaged image memory
            if (imagePtr != IntPtr.Zero)
            {
                Marshal.FreeHGlobal(imagePtr);
            }
        }
    }

    /// <summary>
    /// Detects CUDA include path on the system.
    /// </summary>
    private string DetectCudaIncludePath()
    {
        // Try common CUDA installation paths
        string[] searchPaths =
        {
            "/usr/local/cuda/include",
            "/usr/local/cuda-13.0/include",
            "/usr/local/cuda-12.0/include",
            "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v13.0\\include",
            "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.0\\include"
        };

        foreach (var path in searchPaths)
        {
            if (System.IO.Directory.Exists(path))
            {
                _logger.LogDebug("Found CUDA include path: {Path}", path);
                return path;
            }
        }

        _logger.LogWarning("Could not detect CUDA include path - compilation may fail");
        return string.Empty;
    }

    /// <summary>
    /// Gets the default compute capability for the current system.
    /// </summary>
    private string GetDefaultComputeCapability()
    {
        // TODO: Query actual GPU compute capability using CUDA driver API
        // For now, use a reasonable default (sm_75 = Turing architecture)
        return "sm_75";
    }
}
