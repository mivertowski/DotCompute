# Introduction to Ring Kernels

Ring Kernels are a revolutionary programming model in DotCompute that enables **persistent GPU-resident computation** with actor-style message passing. Unlike traditional kernels that launch, execute, and terminate for each invocation, Ring Kernels remain resident on the GPU, processing messages continuously with near-zero launch overhead.

## What Are Ring Kernels?

Ring Kernels implement the **persistent kernel pattern**, where GPU compute units remain active in a processing loop, consuming messages from lock-free queues and producing results asynchronously. This enables entirely new programming paradigms on GPUs:

### Traditional Kernel Model
```
Host ‚Üí Launch Kernel ‚Üí GPU Executes ‚Üí Kernel Terminates ‚Üí Host
         (5-50Œºs overhead per launch)
```

### Ring Kernel Model
```
Host ‚Üí Launch Once ‚Üí GPU Stays Resident ‚Üí Process Messages Continuously
                        (0Œºs launch overhead after initial launch)
```

## Key Concepts

### 1. Persistent Execution
Ring Kernels run in an infinite loop on the GPU, waiting for and processing messages as they arrive. The kernel lifecycle:

```
Launch ‚Üí Activate ‚Üí [Process Messages] ‚Üí Deactivate ‚Üí Terminate
           ‚Üë               ‚Üì
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. Lock-Free Message Passing
Messages are exchanged through **lock-free ring buffers** using atomic operations:
- **Enqueue**: Compare-and-swap to claim slot, write message
- **Dequeue**: Compare-and-swap to claim message, read data
- **Thread-safe**: Multiple producers and consumers without locks

### 3. Actor-Style Programming
Each kernel instance acts as an independent actor with:
- **Mailbox**: Input queue for receiving messages
- **State**: Persistent local state across messages
- **Behavior**: Message processing logic
- **Output**: Results sent to other actors or host

## Why Use Ring Kernels?

### Performance Benefits

**1. Eliminate Launch Overhead**
- Traditional: 5-50Œºs per kernel launch
- Ring Kernel: One-time launch, then 0Œºs

**2. High Message Throughput**
- CPU simulation: ~10K-100K messages/sec
- GPU (CUDA): ~1M-10M messages/sec
- GPU (Metal/OpenCL): ~500K-5M messages/sec

**3. Low Latency**
- Traditional: Launch overhead + execution time
- Ring Kernel: Immediate message processing (no launch)

### Programming Model Benefits

**1. Reactive Programming**
- Event-driven computation
- Asynchronous message handling
- Natural fit for streaming data

**2. Actor Systems**
- Isolated actors with message passing
- Location transparency
- Fault isolation

**3. Graph Computation**
- Vertex-centric algorithms (Pregel-style)
- Bulk synchronous parallel (BSP) patterns
- Dynamic workload distribution

## Supported Backends

Ring Kernels work across all DotCompute backends:

| Backend | Status | Performance | Platform |
|---------|--------|-------------|----------|
| **CUDA** | ‚úÖ Production | ~1M-10M msgs/sec | NVIDIA GPUs |
| **Metal** | ‚úÖ Production | ~500K-5M msgs/sec | Apple Silicon |
| **OpenCL** | ‚úÖ Production | ~500K-5M msgs/sec | Cross-platform |
| **CPU** | ‚úÖ Simulation | ~10K-100K msgs/sec | All platforms |

## Use Cases

### 1. Graph Analytics
**Problem**: Traditional batch processing inefficient for dynamic graphs

**Solution**: Vertex-centric message passing with Ring Kernels

```csharp
// PageRank with Ring Kernels
[RingKernel(Mode = RingKernelMode.Persistent, Domain = RingKernelDomain.GraphAnalytics)]
public class PageRankVertex
{
    private float _rank = 1.0f;
    private int _outDegree;

    public void ProcessMessage(VertexMessage msg)
    {
        // Accumulate contributions from neighbors
        _rank = 0.15f + 0.85f * msg.Contribution;

        // Send updated rank to outgoing edges
        float contribution = _rank / _outDegree;
        foreach (var neighbor in GetOutEdges())
        {
            SendMessage(neighbor, new VertexMessage { Contribution = contribution });
        }
    }
}
```

### 2. Spatial Simulations
**Problem**: Stencil computations with frequent halo exchanges

**Solution**: Persistent kernels with local communication

```csharp
// Heat diffusion simulation
[RingKernel(Mode = RingKernelMode.Persistent, Domain = RingKernelDomain.SpatialSimulation)]
public class HeatDiffusion
{
    private float _temperature;
    private const float Alpha = 0.1f;

    public void ProcessMessage(HaloMessage msg)
    {
        // Update temperature from neighbors
        _temperature = (1 - 4 * Alpha) * _temperature
                     + Alpha * (msg.North + msg.South + msg.East + msg.West);

        // Send updated value to neighbors
        BroadcastToNeighbors(new HaloMessage { Value = _temperature });
    }
}
```

### 3. Real-Time Event Processing
**Problem**: Low-latency stream processing on GPU

**Solution**: Event-driven Ring Kernels with immediate processing

```csharp
// Real-time anomaly detection
[RingKernel(Mode = RingKernelMode.EventDriven, Domain = RingKernelDomain.ActorModel)]
public class AnomalyDetector
{
    private MovingAverage _average = new();
    private float _threshold = 3.0f;

    public void ProcessEvent(SensorReading reading)
    {
        float deviation = Math.Abs(reading.Value - _average.Current);

        if (deviation > _threshold * _average.StdDev)
        {
            // Anomaly detected - alert immediately
            SendAlert(new AnomalyAlert
            {
                Timestamp = reading.Timestamp,
                Value = reading.Value,
                ExpectedRange = _average.Current ¬± _average.StdDev
            });
        }

        _average.Update(reading.Value);
    }
}
```

### 4. Distributed Actor Systems
**Problem**: Scalable actor-based computation

**Solution**: GPU-resident actors with mailbox-based communication

```csharp
// Distributed key-value store actors
[RingKernel(Mode = RingKernelMode.Persistent, Domain = RingKernelDomain.ActorModel)]
public class KVStoreActor
{
    private Dictionary<int, string> _storage = new();

    public void ProcessMessage(KVMessage msg)
    {
        switch (msg.Type)
        {
            case MessageType.Get:
                var value = _storage.TryGetValue(msg.Key, out var v) ? v : null;
                Reply(new KVResponse { Key = msg.Key, Value = value });
                break;

            case MessageType.Put:
                _storage[msg.Key] = msg.Value;
                Reply(new KVResponse { Success = true });
                break;

            case MessageType.Delete:
                _storage.Remove(msg.Key);
                Reply(new KVResponse { Success = true });
                break;
        }
    }
}
```

## Execution Modes

Ring Kernels support two execution modes:

### Persistent Mode
**Behavior**: Kernel runs continuously until explicitly terminated

**Best For**:
- Long-running services
- Continuous stream processing
- Actor systems with steady workload

**Trade-offs**:
- ‚úÖ Zero launch overhead
- ‚úÖ Immediate message processing
- ‚ùå Consumes GPU resources continuously

```csharp
[RingKernel(Mode = RingKernelMode.Persistent)]
public class PersistentProcessor { }
```

### Event-Driven Mode
**Behavior**: Kernel activates on-demand, processes batch, then idles

**Best For**:
- Bursty workloads
- Power-constrained devices
- Shared GPU resources

**Trade-offs**:
- ‚úÖ Conserves GPU resources
- ‚úÖ Automatic power management
- ‚ùå Small activation overhead (~1-10Œºs)

```csharp
[RingKernel(Mode = RingKernelMode.EventDriven)]
public class EventDrivenProcessor { }
```

## Message Passing Strategies

Choose the right strategy for your workload:

### 1. SharedMemory (Fastest)
**Use For**: Intra-block communication, low capacity (<64KB)

```csharp
[RingKernel(MessagingStrategy = MessagePassingStrategy.SharedMemory)]
public class SharedMemoryKernel { }
```

**Characteristics**:
- ‚ö° Lowest latency (~10ns access)
- üìä Limited capacity (GPU shared memory size)
- üîí Lock-free with atomic operations
- ‚úÖ Best for producer-consumer patterns

### 2. AtomicQueue (Scalable)
**Use For**: Inter-block communication, larger capacity

```csharp
[RingKernel(MessagingStrategy = MessagePassingStrategy.AtomicQueue)]
public class GlobalMemoryKernel { }
```

**Characteristics**:
- ‚ö° Medium latency (~100ns access)
- üìä Large capacity (GPU global memory)
- üîí Lock-free with exponential backoff
- ‚úÖ Best for distributed actors

### 3. P2P (Multi-GPU)
**Use For**: GPU-to-GPU direct transfers

```csharp
[RingKernel(MessagingStrategy = MessagePassingStrategy.P2P)]
public class MultiGPUKernel { }
```

**Characteristics**:
- ‚ö° Low latency (~1Œºs direct copy)
- üîó Requires P2P capable GPUs
- üì° Direct GPU memory access
- ‚úÖ Best for multi-GPU pipelines

### 4. NCCL (Collective)
**Use For**: Multi-GPU reductions and broadcasts

```csharp
[RingKernel(MessagingStrategy = MessagePassingStrategy.NCCL)]
public class CollectiveKernel { }
```

**Characteristics**:
- ‚ö° Optimized collective operations
- üåê Multi-node support
- üìä Scales to hundreds of GPUs
- ‚úÖ Best for distributed training

## Synchronization and Memory Ordering

Ring kernels have unique synchronization needs due to message passing. Unlike regular kernels (which default to relaxed memory ordering), ring kernels default to **Release-Acquire consistency** for correct message visibility.

### Barrier Support

Ring kernels support GPU thread barriers for coordinating threads within a kernel instance:

```csharp
[RingKernel(
    UseBarriers = true,                      // Enable barriers
    BarrierScope = BarrierScope.ThreadBlock, // Sync within thread block
    MemoryConsistency = MemoryConsistencyModel.ReleaseAcquire, // Default for ring kernels
    EnableCausalOrdering = true)]            // Default true for message passing
public static void RingKernelWithBarriers(
    MessageQueue<float> incoming,
    MessageQueue<float> outgoing)
{
    var shared = Kernel.AllocateShared<float>(256);
    int tid = Kernel.ThreadId.X;

    // Phase 1: Process incoming messages into shared memory
    if (incoming.TryDequeue(out var msg))
    {
        shared[tid] = msg;
    }

    Kernel.Barrier();  // Wait for all threads

    // Phase 2: Aggregate and send results
    if (tid == 0)
    {
        float sum = 0;
        for (int i = 0; i < 256; i++)
            sum += shared[i];

        outgoing.Enqueue(sum / 256.0f);
    }
}
```

### Ring Kernel vs Regular Kernel Defaults

Ring kernels have **safer defaults** for message passing:

| Property | Regular Kernel Default | Ring Kernel Default | Reason |
|----------|----------------------|--------------------|---------|
| `MemoryConsistency` | `Relaxed` | `ReleaseAcquire` | Message passing requires causality |
| `EnableCausalOrdering` | `false` | `true` | Ensures message visibility |
| Performance Overhead | 0% | 15% | Acceptable for persistent kernels |

**Key Insight**: Ring kernels run persistently, so the 15% overhead of Release-Acquire consistency is amortized over the kernel's lifetime. This provides safety by default for message-passing patterns.

### When to Use Barriers in Ring Kernels

**Use Barriers**:
- Coordinating shared memory access for message batching
- Implementing reduction operations on incoming messages
- Multi-phase message processing with dependencies
- Aggregating results before sending outgoing messages

**Example: Message Batch Processing**:
```csharp
[RingKernel(
    UseBarriers = true,
    BarrierScope = BarrierScope.ThreadBlock)]
public static void BatchProcessor(
    MessageQueue<int> incoming,
    MessageQueue<int> outgoing)
{
    var shared = Kernel.AllocateShared<int>(256);
    int tid = Kernel.ThreadId.X;

    // Each thread dequeues one message
    shared[tid] = incoming.TryDequeue(out var msg) ? msg : 0;

    Kernel.Barrier();  // Ensure all messages loaded

    // Thread 0 aggregates batch
    if (tid == 0)
    {
        int batchSum = 0;
        for (int i = 0; i < 256; i++)
            batchSum += shared[i];

        outgoing.Enqueue(batchSum);
    }
}
```

**See Also**: [Barriers and Memory Ordering](../advanced/barriers-and-memory-ordering.md) for comprehensive details

## Domain Optimizations

Specify your application domain for automatic optimizations:

### General
```csharp
[RingKernel(Domain = RingKernelDomain.General)]
```
No specific optimizations. Good default.

### GraphAnalytics
```csharp
[RingKernel(Domain = RingKernelDomain.GraphAnalytics)]
```
Optimized for:
- Irregular memory access patterns
- Load imbalance
- Grid synchronization (BSP)

### SpatialSimulation
```csharp
[RingKernel(Domain = RingKernelDomain.SpatialSimulation)]
```
Optimized for:
- Regular memory access patterns
- Local communication
- Halo exchange

### ActorModel
```csharp
[RingKernel(Domain = RingKernelDomain.ActorModel)]
```
Optimized for:
- Message-heavy workloads
- Low-latency delivery
- Dynamic workload distribution

## Getting Started

### 1. Define Your Ring Kernel

```csharp
using DotCompute.Abstractions.RingKernels;

[RingKernel(
    Mode = RingKernelMode.Persistent,
    MessagingStrategy = MessagePassingStrategy.AtomicQueue,
    Domain = RingKernelDomain.General)]
public class MyFirstRingKernel
{
    private int _messageCount = 0;

    public void ProcessMessage(int data)
    {
        // Process incoming message
        int result = data * 2;
        _messageCount++;

        // Send result
        SendResult(result);
    }
}
```

### 2. Launch the Kernel

```csharp
using DotCompute.Backends.CUDA.RingKernels; // or Metal, OpenCL

// Create runtime
var logger = loggerFactory.CreateLogger<CudaRingKernelRuntime>();
var compiler = new CudaRingKernelCompiler(compilerLogger);
var runtime = new CudaRingKernelRuntime(logger, compiler);

// Launch kernel (stays resident)
await runtime.LaunchAsync("my_kernel", gridSize: 1, blockSize: 256);

// Activate processing
await runtime.ActivateAsync("my_kernel");
```

### 3. Send Messages

```csharp
// Send 1000 messages
for (int i = 0; i < 1000; i++)
{
    var message = KernelMessage<int>.CreateData(
        senderId: 0,
        receiverId: -1,
        payload: i
    );

    await runtime.SendMessageAsync("my_kernel", message);
}
```

### 4. Monitor Status

```csharp
// Get kernel status
var status = await runtime.GetStatusAsync("my_kernel");
Console.WriteLine($"Active: {status.IsActive}");
Console.WriteLine($"Messages Processed: {status.MessagesProcessed}");

// Get performance metrics
var metrics = await runtime.GetMetricsAsync("my_kernel");
Console.WriteLine($"Throughput: {metrics.ThroughputMsgsPerSec:F0} msgs/sec");
Console.WriteLine($"Avg Latency: {metrics.AvgProcessingTimeMs:F2}ms");
```

### 5. Cleanup

```csharp
// Deactivate (pause processing)
await runtime.DeactivateAsync("my_kernel");

// Terminate (cleanup resources)
await runtime.TerminateAsync("my_kernel");

// Dispose runtime
await runtime.DisposeAsync();
```

## Best Practices

### 1. Choose the Right Mode
- **Persistent**: Steady workloads, low latency critical
- **EventDriven**: Bursty workloads, power efficiency important

### 2. Size Your Queues Appropriately
- Too small: Messages dropped, throughput limited
- Too large: Memory waste, cache pollution
- **Rule of thumb**: 256-1024 messages per queue

### 3. Use Appropriate Message Sizes
- Keep messages small (< 256 bytes ideal)
- Use indirection for large data (pointers to buffers)
- Pad to avoid false sharing (64-byte cache lines)

### 4. Monitor Queue Utilization
```csharp
var metrics = await runtime.GetMetricsAsync("kernel_id");
if (metrics.InputQueueUtilization > 0.8)
{
    // Queue nearly full - increase capacity or add more kernels
}
```

### 5. Handle Termination Gracefully
```csharp
// Set timeout for graceful shutdown
var cts = new CancellationTokenSource(TimeSpan.FromSeconds(5));
await runtime.TerminateAsync("kernel_id", cts.Token);
```

## Performance Expectations

### Message Throughput

| Backend | Single Kernel | Multi-Kernel (4x) |
|---------|---------------|-------------------|
| CUDA | 1-10M msgs/sec | 4-40M msgs/sec |
| Metal | 500K-5M msgs/sec | 2-20M msgs/sec |
| OpenCL | 500K-5M msgs/sec | 2-20M msgs/sec |
| CPU | 10-100K msgs/sec | 40-400K msgs/sec |

### Latency

| Operation | Typical Latency |
|-----------|----------------|
| Launch (one-time) | 1-10ms |
| Activate/Deactivate | 10-100Œºs |
| Message enqueue (host) | 100-500ns |
| Message processing (GPU) | 10-100ns |
| Terminate | 10-100ms |

### Comparison vs Traditional Kernels

For a workload with 1000 invocations:

**Traditional Kernels**:
- Launch overhead: 1000 √ó 25Œºs = 25ms
- Execution time: Variable
- **Total**: 25ms + execution

**Ring Kernels**:
- Launch overhead: 1 √ó 5ms = 5ms (one-time)
- Execution time: Variable (same as traditional)
- **Total**: 5ms + execution

**Speedup**: ~5x reduction in overhead for this example

## Next Steps

Ready to dive deeper? Check out these resources:

- **[Advanced Ring Kernel Programming](ring-kernels-advanced.md)** - Deep dive into patterns and optimization
- **[Ring Kernel API Reference](/api/DotCompute.Abstractions.RingKernels.html)** - Complete API documentation
- **[Multi-GPU Programming](multi-gpu.md)** - Using Ring Kernels across multiple GPUs
- **[Performance Tuning](performance-tuning.md)** - Optimize your Ring Kernel performance

## Summary

Ring Kernels enable **persistent GPU-resident computation** with:
- ‚úÖ Zero launch overhead after initial launch
- ‚úÖ Actor-style message passing with lock-free queues
- ‚úÖ Cross-backend support (CUDA, Metal, OpenCL, CPU)
- ‚úÖ Multiple execution modes and message strategies
- ‚úÖ Domain-specific optimizations

Perfect for:
- Graph analytics and network algorithms
- Spatial simulations and stencil computations
- Real-time event processing and streaming
- Distributed actor systems

Start building high-performance, GPU-resident applications today!
