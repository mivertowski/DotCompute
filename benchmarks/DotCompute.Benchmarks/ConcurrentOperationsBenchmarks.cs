using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Jobs;
using DotCompute.Abstractions;
using DotCompute.Core.Compute;
using Microsoft.Extensions.Logging.Abstractions;
using System.Collections.Concurrent;

namespace DotCompute.Benchmarks;

/// <summary>
/// Benchmarks for concurrent operations performance.
/// Tests thread safety, contention, and scaling characteristics under concurrent load.
/// </summary>
[MemoryDiagnoser]
[ThreadingDiagnoser]
[SimpleJob(RuntimeMoniker.Net90)]
[RPlotExporter]
[MinColumn, MaxColumn, MeanColumn, MedianColumn]
public class ConcurrentOperationsBenchmarks
{
    private IAcceleratorManager _acceleratorManager = null!;
    private IAccelerator _accelerator = null!;
    private IMemoryManager _memoryManager = null!;
    private readonly ConcurrentBag<IMemoryBuffer> _buffers = new();
    private readonly object _lockObject = new();

    [Params(1, 2, 4, 8, 16)]
    public int ConcurrentThreads { get; set; }

    [Params(1024, 16384, 65536, 262144)]
    public int DataSize { get; set; }

    [Params("MemoryOperations", "KernelExecution", "Mixed", "HighContention")]
    public string ConcurrencyType { get; set; } = "MemoryOperations";

    private float[][] _threadData = null!;
    private readonly SemaphoreSlim _semaphore = new(1, 1);
    private readonly ConcurrentQueue<float[]> _workQueue = new();

    [GlobalSetup]
    public async Task Setup()
    {
        var logger = new NullLogger<DefaultAcceleratorManager>();
        _acceleratorManager = new DefaultAcceleratorManager(logger);
        
        var cpuProvider = new CpuAcceleratorProvider(new NullLogger<CpuAcceleratorProvider>());
        _acceleratorManager.RegisterProvider(cpuProvider);
        await _acceleratorManager.InitializeAsync();
        
        _accelerator = _acceleratorManager.Default;
        _memoryManager = _accelerator.Memory;
        
        SetupTestData();
    }

    private void SetupTestData()
    {
        _threadData = new float[ConcurrentThreads][];
        var random = new Random(42);
        
        for (int t = 0; t < ConcurrentThreads; t++)\n        {\n            _threadData[t] = new float[DataSize];\n            for (int i = 0; i < DataSize; i++)\n            {\n                _threadData[t][i] = (float)(random.NextDouble() * 2.0 - 1.0);\n            }\n        }\n        \n        // Fill work queue for producer-consumer tests\n        for (int i = 0; i < ConcurrentThreads * 10; i++)\n        {\n            var workItem = new float[DataSize / 10];\n            for (int j = 0; j < workItem.Length; j++)\n            {\n                workItem[j] = (float)random.NextDouble();\n            }\n            _workQueue.Enqueue(workItem);\n        }\n    }\n\n    [GlobalCleanup]\n    public async Task Cleanup()\n    {\n        while (_buffers.TryTake(out var buffer))\n        {\n            if (!buffer.IsDisposed)\n                await buffer.DisposeAsync();\n        }\n        \n        await _acceleratorManager.DisposeAsync();\n        _semaphore.Dispose();\n    }\n\n    [IterationCleanup]\n    public async Task IterationCleanup()\n    {\n        var buffersToDispose = new List<IMemoryBuffer>();\n        while (_buffers.TryTake(out var buffer))\n        {\n            buffersToDispose.Add(buffer);\n        }\n        \n        foreach (var buffer in buffersToDispose)\n        {\n            if (!buffer.IsDisposed)\n                await buffer.DisposeAsync();\n        }\n    }\n\n    [Benchmark(Baseline = true)]\n    public async Task SingleThreadExecution()\n    {\n        await ExecuteConcurrencyType(ConcurrencyType, 1);\n    }\n\n    [Benchmark]\n    public async Task ConcurrentExecution()\n    {\n        await ExecuteConcurrencyType(ConcurrencyType, ConcurrentThreads);\n    }\n\n    private async Task ExecuteConcurrencyType(string type, int threadCount)\n    {\n        switch (type)\n        {\n            case \"MemoryOperations\":\n                await ExecuteConcurrentMemoryOperations(threadCount);\n                break;\n            case \"KernelExecution\":\n                await ExecuteConcurrentKernelExecution(threadCount);\n                break;\n            case \"Mixed\":\n                await ExecuteMixedConcurrentOperations(threadCount);\n                break;\n            case \"HighContention\":\n                await ExecuteHighContentionScenario(threadCount);\n                break;\n        }\n    }\n\n    private async Task ExecuteConcurrentMemoryOperations(int threadCount)\n    {\n        var tasks = new List<Task>();\n        \n        for (int t = 0; t < threadCount; t++)\n        {\n            int threadIndex = t;\n            tasks.Add(Task.Run(async () =>\n            {\n                var threadId = Thread.CurrentThread.ManagedThreadId;\n                var data = _threadData[threadIndex % _threadData.Length];\n                \n                // Multiple memory operations per thread\n                for (int op = 0; op < 5; op++)\n                {\n                    var buffer = await _memoryManager.AllocateAsync(data.Length * sizeof(float));\n                    await buffer.CopyFromHostAsync(data);\n                    \n                    var result = new float[data.Length];\n                    await buffer.CopyToHostAsync(result);\n                    \n                    _buffers.Add(buffer);\n                    \n                    // Small delay to increase contention\n                    await Task.Delay(1);\n                }\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n    }\n\n    private async Task ExecuteConcurrentKernelExecution(int threadCount)\n    {\n        var tasks = new List<Task>();\n        \n        for (int t = 0; t < threadCount; t++)\n        {\n            int threadIndex = t;\n            tasks.Add(Task.Run(async () =>\n            {\n                var data = _threadData[threadIndex % _threadData.Length];\n                \n                // Simulate kernel compilation and execution\n                await SimulateKernelCompilation($\"thread_{threadIndex}\");\n                \n                var inputBuffer = await _memoryManager.AllocateAndCopyAsync(data);\n                var outputBuffer = await _memoryManager.AllocateAsync(data.Length * sizeof(float));\n                \n                // Simulate kernel execution\n                await SimulateKernelExecution(inputBuffer, outputBuffer);\n                \n                var result = new float[data.Length];\n                await outputBuffer.CopyToHostAsync(result);\n                \n                _buffers.Add(inputBuffer);\n                _buffers.Add(outputBuffer);\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n    }\n\n    private async Task ExecuteMixedConcurrentOperations(int threadCount)\n    {\n        var tasks = new List<Task>();\n        \n        for (int t = 0; t < threadCount; t++)\n        {\n            int threadIndex = t;\n            tasks.Add(Task.Run(async () =>\n            {\n                var data = _threadData[threadIndex % _threadData.Length];\n                \n                // Mix of operations based on thread index\n                if (threadIndex % 3 == 0)\n                {\n                    // Memory-intensive operations\n                    await ExecuteMemoryIntensiveWork(data);\n                }\n                else if (threadIndex % 3 == 1)\n                {\n                    // Compute-intensive operations\n                    await ExecuteComputeIntensiveWork(data);\n                }\n                else\n                {\n                    // Mixed operations\n                    await ExecuteMixedWork(data);\n                }\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n    }\n\n    private async Task ExecuteHighContentionScenario(int threadCount)\n    {\n        var sharedResource = await _memoryManager.AllocateAsync(DataSize * sizeof(float));\n        _buffers.Add(sharedResource);\n        \n        var tasks = new List<Task>();\n        var contentionCounter = 0;\n        \n        for (int t = 0; t < threadCount; t++)\n        {\n            int threadIndex = t;\n            tasks.Add(Task.Run(async () =>\n            {\n                var data = _threadData[threadIndex % _threadData.Length];\n                \n                // High contention operations\n                for (int i = 0; i < 10; i++)\n                {\n                    // Lock-based contention\n                    lock (_lockObject)\n                    {\n                        contentionCounter++;\n                        Thread.Sleep(1); // Simulate work under lock\n                    }\n                    \n                    // Semaphore-based throttling\n                    await _semaphore.WaitAsync();\n                    try\n                    {\n                        await sharedResource.CopyFromHostAsync(data.AsMemory(0, Math.Min(data.Length, DataSize)));\n                        await Task.Delay(1);\n                    }\n                    finally\n                    {\n                        _semaphore.Release();\n                    }\n                    \n                    // Atomic operations contention\n                    Interlocked.Increment(ref contentionCounter);\n                }\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n    }\n\n    private async Task ExecuteMemoryIntensiveWork(float[] data)\n    {\n        // Multiple buffer allocations and transfers\n        var buffers = new List<IMemoryBuffer>();\n        \n        for (int i = 0; i < 3; i++)\n        {\n            var buffer = await _memoryManager.AllocateAndCopyAsync(data);\n            buffers.Add(buffer);\n            \n            // Copy data between buffers\n            var tempData = new float[data.Length];\n            await buffer.CopyToHostAsync(tempData);\n            \n            // Modify data slightly\n            for (int j = 0; j < tempData.Length; j++)\n            {\n                tempData[j] *= 1.1f;\n            }\n            \n            await buffer.CopyFromHostAsync(tempData);\n        }\n        \n        foreach (var buffer in buffers)\n        {\n            _buffers.Add(buffer);\n        }\n    }\n\n    private async Task ExecuteComputeIntensiveWork(float[] data)\n    {\n        var buffer = await _memoryManager.AllocateAndCopyAsync(data);\n        \n        // Simulate compute-intensive kernel\n        await SimulateComputeKernel(buffer);\n        \n        var result = new float[data.Length];\n        await buffer.CopyToHostAsync(result);\n        \n        _buffers.Add(buffer);\n    }\n\n    private async Task ExecuteMixedWork(float[] data)\n    {\n        // Combination of memory and compute operations\n        var buffer1 = await _memoryManager.AllocateAndCopyAsync(data);\n        var buffer2 = await _memoryManager.AllocateAsync(data.Length * sizeof(float));\n        \n        await SimulateKernelExecution(buffer1, buffer2);\n        \n        var result = new float[data.Length];\n        await buffer2.CopyToHostAsync(result);\n        \n        _buffers.Add(buffer1);\n        _buffers.Add(buffer2);\n    }\n\n    [Benchmark]\n    public async Task ProducerConsumerPattern()\n    {\n        var producerTasks = new List<Task>();\n        var consumerTasks = new List<Task>();\n        var processedCount = 0;\n        \n        // Producers\n        for (int i = 0; i < ConcurrentThreads / 2; i++)\n        {\n            producerTasks.Add(Task.Run(async () =>\n            {\n                for (int j = 0; j < 10; j++)\n                {\n                    var workItem = new float[DataSize / 100];\n                    for (int k = 0; k < workItem.Length; k++)\n                    {\n                        workItem[k] = (float)Random.Shared.NextDouble();\n                    }\n                    \n                    _workQueue.Enqueue(workItem);\n                    await Task.Delay(5); // Simulate work\n                }\n            }));\n        }\n        \n        // Consumers\n        for (int i = 0; i < ConcurrentThreads / 2; i++)\n        {\n            consumerTasks.Add(Task.Run(async () =>\n            {\n                while (processedCount < ConcurrentThreads * 10)\n                {\n                    if (_workQueue.TryDequeue(out var workItem))\n                    {\n                        var buffer = await _memoryManager.AllocateAndCopyAsync(workItem);\n                        \n                        // Simulate processing\n                        await Task.Delay(10);\n                        \n                        _buffers.Add(buffer);\n                        Interlocked.Increment(ref processedCount);\n                    }\n                    else\n                    {\n                        await Task.Delay(1);\n                    }\n                }\n            }));\n        }\n        \n        await Task.WhenAll(producerTasks.Concat(consumerTasks));\n    }\n\n    [Benchmark]\n    public async Task ConcurrentMemoryPool()\n    {\n        // Test concurrent access to memory pool\n        var tasks = new List<Task>();\n        \n        for (int t = 0; t < ConcurrentThreads; t++)\n        {\n            tasks.Add(Task.Run(async () =>\n            {\n                var buffers = new List<IMemoryBuffer>();\n                \n                // Allocate multiple buffers rapidly\n                for (int i = 0; i < 20; i++)\n                {\n                    var size = (DataSize / 20) * (i + 1);\n                    var buffer = await _memoryManager.AllocateAsync(size * sizeof(float));\n                    buffers.Add(buffer);\n                }\n                \n                // Free half of them\n                for (int i = 0; i < buffers.Count / 2; i++)\n                {\n                    await buffers[i].DisposeAsync();\n                }\n                \n                // Reallocate (should reuse from pool)\n                for (int i = buffers.Count / 2; i < buffers.Count; i++)\n                {\n                    var size = (DataSize / 20) * (i + 1);\n                    var buffer = await _memoryManager.AllocateAsync(size * sizeof(float));\n                    buffers.Add(buffer);\n                }\n                \n                foreach (var buffer in buffers.Skip(buffers.Count / 2))\n                {\n                    _buffers.Add(buffer);\n                }\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n    }\n\n    [Benchmark]\n    public async Task ThreadSafetyStressTest()\n    {\n        var tasks = new List<Task>();\n        var exceptions = new ConcurrentBag<Exception>();\n        \n        for (int t = 0; t < ConcurrentThreads; t++)\n        {\n            int threadIndex = t;\n            tasks.Add(Task.Run(async () =>\n            {\n                try\n                {\n                    var data = _threadData[threadIndex % _threadData.Length];\n                    \n                    // Stress test with rapid operations\n                    for (int i = 0; i < 50; i++)\n                    {\n                        var buffer = await _memoryManager.AllocateAsync(DataSize * sizeof(float));\n                        await buffer.CopyFromHostAsync(data);\n                        \n                        var result = new float[DataSize];\n                        await buffer.CopyToHostAsync(result);\n                        \n                        _buffers.Add(buffer);\n                        \n                        // No delay to maximize contention\n                    }\n                }\n                catch (Exception ex)\n                {\n                    exceptions.Add(ex);\n                }\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n        \n        if (!exceptions.IsEmpty)\n        {\n            throw new AggregateException(\"Thread safety violations detected\", exceptions);\n        }\n    }\n\n    [Benchmark]\n    public double ConcurrencyScalingEfficiency()\n    {\n        // Calculate scaling efficiency\n        var singleThreadTime = 100.0; // Simulated baseline (ms)\n        var multiThreadTime = singleThreadTime / ConcurrentThreads * 1.3; // With 30% overhead\n        \n        var idealSpeedup = ConcurrentThreads;\n        var actualSpeedup = singleThreadTime / multiThreadTime;\n        \n        return actualSpeedup / idealSpeedup * 100.0; // Efficiency percentage\n    }\n\n    [Benchmark]\n    public async Task ContentionMeasurement()\n    {\n        var contentionCounter = 0;\n        var tasks = new List<Task>();\n        var stopwatch = System.Diagnostics.Stopwatch.StartNew();\n        \n        for (int t = 0; t < ConcurrentThreads; t++)\n        {\n            tasks.Add(Task.Run(async () =>\n            {\n                for (int i = 0; i < 100; i++)\n                {\n                    var lockTaken = false;\n                    var lockStart = stopwatch.ElapsedTicks;\n                    \n                    lock (_lockObject)\n                    {\n                        lockTaken = true;\n                        var waitTime = stopwatch.ElapsedTicks - lockStart;\n                        if (waitTime > 1000) // If waited more than threshold\n                        {\n                            Interlocked.Increment(ref contentionCounter);\n                        }\n                        \n                        // Simulate work under lock\n                        Thread.SpinWait(1000);\n                    }\n                }\n            }));\n        }\n        \n        await Task.WhenAll(tasks);\n        stopwatch.Stop();\n        \n        Console.WriteLine($\"Contention events: {contentionCounter}\");\n    }\n\n    // Helper methods\n    private async Task SimulateKernelCompilation(string kernelName)\n    {\n        // Simulate kernel compilation time\n        await Task.Delay(Random.Shared.Next(1, 5));\n    }\n\n    private async Task SimulateKernelExecution(IMemoryBuffer input, IMemoryBuffer output)\n    {\n        // Simulate kernel execution\n        await Task.Delay(Random.Shared.Next(5, 15));\n        \n        // Simulate data processing\n        var size = (int)(input.SizeInBytes / sizeof(float));\n        var data = new float[size];\n        await input.CopyToHostAsync(data);\n        \n        for (int i = 0; i < data.Length; i++)\n        {\n            data[i] *= 2.0f;\n        }\n        \n        await output.CopyFromHostAsync(data);\n    }\n\n    private async Task SimulateComputeKernel(IMemoryBuffer buffer)\n    {\n        // Simulate compute-intensive work\n        await Task.Delay(Random.Shared.Next(10, 20));\n        \n        var size = (int)(buffer.SizeInBytes / sizeof(float));\n        var data = new float[size];\n        await buffer.CopyToHostAsync(data);\n        \n        // Simulate heavy computation\n        for (int i = 0; i < data.Length; i++)\n        {\n            data[i] = (float)Math.Sin(data[i]) * (float)Math.Cos(data[i]);\n        }\n        \n        await buffer.CopyFromHostAsync(data);\n    }\n}