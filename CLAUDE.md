# DotCompute - Claude Code Context

## ğŸ¯ Core Principles

**ALWAYS**:
- Quality first - no shortcuts, no compromises
- Production-grade code only
- Test-driven development
- Native AOT compatibility
- Organize files in proper directories (never root!)

## ğŸ“¦ Project Overview

**DotCompute** v0.6.0 - NuGet Packaging & Infrastructure Release for .NET 9+

- **Repository**: https://github.com/mivertowski/DotCompute
- **Documentation**: https://mivertowski.github.io/DotCompute/
- **Performance**: CPU 3.7x (SIMD), GPU 21-92x (CUDA on RTX 2000 Ada, CC 8.9)
- **Code Quality**: Pristine build with only 1 documented NoWarn (CA1873)

## ğŸš€ Quick Build Commands

```bash
# Build solution
dotnet build DotCompute.sln --configuration Release

# Run all tests (recommended - auto-configures WSL2)
./scripts/run-tests.sh DotCompute.sln --configuration Release

# Run specific categories
./scripts/run-tests.sh DotCompute.sln --filter "Category=Unit" --configuration Release
./scripts/run-tests.sh DotCompute.sln --filter "Category=Hardware" --configuration Release  # GPU required

# Run CUDA tests (with WSL2 auto-configuration)
./scripts/run-tests.sh tests/Hardware/DotCompute.Hardware.Cuda.Tests/DotCompute.Hardware.Cuda.Tests.csproj

# Manual test run (requires LD_LIBRARY_PATH set for WSL2)
dotnet test DotCompute.sln --configuration Release

# Clean
dotnet clean DotCompute.sln
```

## ğŸ—ï¸ Architecture (4 Layers)

```
DotCompute/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Core/                          # Abstractions, Memory, Runtime
â”‚   â”œâ”€â”€ Backends/                      # CPU, CUDA, OpenCL, Metal
â”‚   â”œâ”€â”€ Extensions/                    # Algorithms, LINQ
â”‚   â””â”€â”€ Runtime/                       # Generators, Analyzers, Plugins
â””â”€â”€ tests/
    â”œâ”€â”€ Unit/                          # Component tests
    â”œâ”€â”€ Integration/                   # Cross-component tests
    â”œâ”€â”€ Hardware/                      # GPU-specific tests
    â””â”€â”€ Shared/                        # Test utilities
```

## âœ… Production-Ready Features

**Backend Infrastructure**:
- âœ… CPU Backend (AVX2/AVX512/NEON SIMD - 3.7x speedup)
- âœ… CUDA Backend (CC 5.0-8.9, P2P, NCCL, Ring Kernels - 21-92x speedup)
- âš ï¸ OpenCL Backend (EXPERIMENTAL - NVIDIA, AMD, Intel, ARM Mali, Qualcomm Adreno)
- âœ… Metal Backend (FEATURE-COMPLETE - MPS, MSL translation, Ring Kernels, memory pooling)
- âœ… Memory Management (90% allocation reduction, P2P transfers)

**Developer Tooling**:
- âœ… Source Generators ([Kernel] attribute â†’ auto-optimization)
- âœ… Roslyn Analyzers (12 diagnostic rules DC001-DC012)
- âœ… IDE Integration (5 automated code fixes, real-time feedback)
- âœ… Cross-Backend Debugging (CPU vs GPU validation)
- âœ… Adaptive Optimization (ML-powered backend selection)

**Advanced APIs**:
- âœ… Ring Kernel System (persistent GPU computation, actor model)
- âœ… GPU Timing API (1ns resolution CC 6.0+, 4 calibration strategies)
- âœ… Barrier API (ThreadBlock, Grid, Warp, Named barriers - <20ns)
- âœ… Memory Ordering API (3 consistency models, acquire-release semantics)
- âœ… LINQ Extensions (Phase 6: GPU compilation CUDA/OpenCL/Metal, 80% complete)

**Runtime & Integration**:
- âœ… DI Integration (Microsoft.Extensions.DependencyInjection)
- âœ… Plugin System (hot-reload capability)
- âœ… Native AOT (sub-10ms startup)

## ğŸ”§ Critical System Info

**CUDA Configuration**:
- CUDA 13.0 at `/usr/local/cuda`
- GPU: NVIDIA RTX 2000 Ada (Compute Capability 8.9)
- Driver: 581.15
- **Always use**: `CudaCapabilityManager.GetTargetComputeCapability()`

**WSL2 CUDA Setup** (CRITICAL for Windows developers):
- NVIDIA libraries in `/usr/lib/wsl/lib/` (NOT `/usr/lib/x86_64-linux-gnu/`)
- Must set: `export LD_LIBRARY_PATH="/usr/lib/wsl/lib:$LD_LIBRARY_PATH"`
- Use: `./scripts/run-tests.sh` (handles WSL2 environment automatically)
- Or use: `./scripts/ci/setup-environment.sh` for full environment setup
- See: `docs/guides/wsl2-setup.md` for detailed configuration
- **Common Error**: CUDA_ERROR_NO_DEVICE (100) means library path not set

**Key Components**:
1. **Kernel System**: `IKernelCompiler`, `KernelDefinition`, `ICompiledKernel`
2. **Memory**: `UnifiedBuffer<T>`, `MemoryPool`, `P2PManager`
3. **Backend**: `IAccelerator`, `IComputeService`, `CompilationOptions`
4. **Runtime**: `IComputeOrchestrator`, `KernelExecutionService`
5. **Debugging**: `IKernelDebugService`, `DebugIntegratedOrchestrator`
6. **Optimization**: `AdaptiveBackendSelector`, `PerformanceOptimizedOrchestrator`

## ğŸ“ Development Guidelines

**Native AOT**:
- No runtime code generation
- Use source generators for compile-time codegen
- Avoid reflection (use attributes where needed)

**Memory Safety**:
- Use `UnifiedBuffer<T>` for cross-device memory
- Implement `IDisposable` properly
- Use memory pooling for frequent allocations
- Validate buffer bounds in kernels

**Testing**:
- Unit tests for all public APIs
- Hardware tests check device availability
- Use `[SkippableFact]` for hardware-specific tests
- Target: ~80% code coverage

**CUDA**:
- Dynamic compute capability detection (don't hardcode)
- Use CUBIN for CC >= 7.0, PTX for older
- Support both compilation paths

## ğŸ¯ Common Tasks

**Add New Kernel (Modern - v0.2.0+)**:
1. Add `[Kernel]` attribute to static method
2. Use `Kernel.ThreadId.X/Y/Z` for threading
3. Add bounds checking: `if (idx < length)`
4. Source generator creates wrapper automatically
5. IDE analyzers provide real-time feedback

**Debug CUDA Issues**:
1. Check capability: `CudaCapabilityManager.GetTargetComputeCapability()`
2. Verify CUDA: `/usr/local/cuda/bin/nvcc --version`
3. Check compilation logs in `CudaKernelCompiler`
4. Use `cuda-memcheck` for memory errors
5. Enable debug: `GenerateDebugInfo = true`

**Performance Optimization**:
1. Profile with BenchmarkDotNet (`benchmarks/`)
2. Use SIMD intrinsics for CPU
3. Optimize memory access patterns for GPU
4. Leverage memory pooling
5. Use P2P for multi-GPU

## ğŸ“Š Current Status (v0.5.3)

**Ring Kernel System**:
- âœ… **Phase 1 COMPLETE**: MemoryPack Integration (43/43 tests passing)
  - Auto-discovery of `[MemoryPackable]` types via Roslyn
  - Batch CUDA code generation for 10+ message types
  - MSBuild integration for pre-build codegen
  - Performance: <100ns serialization/deserialization
  - Zero manual CUDA coding required
- âœ… **Phase 2 COMPLETE**: CPU Ring Kernel Implementation (43/43 tests passing)
  - Thread-based persistent kernel execution
  - Message queue bridge infrastructure for IRingKernelMessage types
  - Echo mode with intelligent message transformation (VectorAdd, etc.)
  - Full lifecycle management (Launch, Activate, Deactivate, Terminate)
  - Telemetry and metrics tracking
  - Adaptive backoff for CPU efficiency
- âœ… **Phase 3 COMPLETE**: CUDA Ring Kernel Implementation (115/122 tests - 94.3%)
  - End-to-end message processing with MemoryPack serialization
  - 6-stage compilation pipeline (Discovery â†’ CodeGen â†’ PTX â†’ Module â†’ Functions â†’ Result)
  - Performance: ~1.24Î¼s serialization, ~1.01Î¼s deserialization
  - Resource validation and cleanup (7 tests)
  - GPU-resident persistent kernels with CUDA
- âœ… **Phase 4 COMPLETE**: Multi-GPU coordination infrastructure
  - Single GPU system (RTX 2000 Ada) - multi-GPU tests N/A
  - P2P memory transfer infrastructure ready
  - Cross-GPU barrier foundations in place
- âœ… **Phase 5 COMPLETE**: Performance & Observability
  - 5.1: Performance Profiling & Optimization âœ…
  - 5.2: Advanced Messaging Patterns âœ…
  - 5.3: Fault Tolerance & Resilience âœ…
  - 5.4: Observability & Distributed Tracing âœ… (94 tests passing)
    - OpenTelemetry integration (ActivitySource, Meter)
    - Prometheus-compatible metrics exporter
    - Health check infrastructure (94 tests)

**LINQ Extensions**:
- âœ… Phase 6: GPU Integration (80% - 43/54 tests)
  - GPU kernel generation (CUDA, OpenCL, Metal)
  - Automatic backend selection
  - Kernel fusion optimization
  - Filter compaction
- â³ Future: Advanced operations (Join, GroupBy, OrderBy)

## ğŸ› Known Limitations

1. **LINQ**: 80% complete, missing Join/GroupBy/OrderBy
2. **OpenCL Backend**: Experimental - cross-platform support in progress
3. **Metal Backend**: Feature-complete, MSL translation works
4. **ROCm Backend**: Placeholder only
5. **Hardware Tests**: Require CC 5.0+ NVIDIA GPU

## âš ï¸ WSL2 GPU Memory Limitations (CRITICAL)

### The Problem

WSL2 has **fundamental limitations** with GPU memory coherence that affect persistent kernel modes and real-time CPU-GPU communication:

1. **System-Scope Atomics Don't Work Reliably**
   - `cuda::memory_order_system` and `__threadfence_system()` don't provide reliable CPU-GPU visibility
   - GPU kernels cannot reliably see host memory updates in real-time
   - This is due to WSL2's GPU virtualization layer (GPU-PV)

2. **Unified Memory is Limited**
   - CUDA managed memory (`cudaMallocManaged`) has restricted functionality
   - Memory cannot spill from VRAM to system RAM like on native Linux
   - Large datasets that exceed VRAM fail instead of using system memory

3. **Persistent Kernel Mode Doesn't Work**
   - Ring kernels that poll for messages via tail pointer updates fail
   - Kernel never sees host-side updates to shared memory
   - Must use EventDriven mode with kernel relaunch instead

### Impact on Ring Kernels

| Feature | Native Linux | WSL2 |
|---------|-------------|------|
| Persistent kernel mode | âœ… Works (<1ms latency) | âŒ Fails (memory visibility) |
| EventDriven kernel mode | âœ… Works | âœ… Works (~5s latency) |
| System-scope atomics | âœ… Works | âŒ Unreliable |
| Unified memory spill | âœ… Works | âŒ Limited |
| `is_active` flag polling | âœ… Works | âŒ Kernel never sees updates |

### Workarounds Implemented

1. **Start-Active Pattern**: Kernels start with `is_active=1` already set, avoiding mid-execution activation
2. **EventDriven Mode**: Kernel processes available messages then terminates, host relaunches for new messages
3. **Bridge Transfer**: Messages queued on host, transferred to GPU buffer, kernel relaunched to process

### Performance Implications

- **Native Linux**: Sub-millisecond message latency with persistent kernels
- **WSL2**: ~5 second latency due to kernel relaunch overhead
- **Optimization**: Bridge uses SpinWait+Yield polling (sub-ms response when kernel is fast)

### Feature Request Channels

To request improved GPU memory coherence in WSL2:

1. **Microsoft WSL Repository**: https://github.com/microsoft/WSL/issues
   - Related: [Issue #7198](https://github.com/microsoft/wslg/issues/357) - Shared memory space issues
   - Related: [Issue #8447](https://github.com/microsoft/WSL/issues/8447) - CUDA out of memory
   - Related: [Issue #3789](https://github.com/Microsoft/WSL/issues/3789) - OpenCL/CUDA support

2. **Microsoft WSLg Repository** (GPU-specific): https://github.com/microsoft/wslg/issues

3. **NVIDIA CUDA on WSL**: https://docs.nvidia.com/cuda/wsl-user-guide/
   - Report issues via NVIDIA Developer Forums

### Recommendation

For production GPU-native actor systems requiring <10ms latency:
- **Use native Linux** (bare metal or VM with GPU passthrough)
- WSL2 is suitable for development and testing only

## ğŸ“‚ Important Files

- `DotCompute.sln` - Solution file
- `Directory.Build.props` / `Directory.Build.targets` - Build config
- `Directory.Packages.props` - Package versions
- `scripts/` - Test and build scripts
- `docs/` - Documentation (29 guides)
- `benchmarks/` - Performance benchmarks

## ğŸ› ï¸ Environment

- .NET 9.0 SDK or later
- C# 13 language features
- Visual Studio 2022 17.8+ or VS Code
- CUDA Toolkit 12.0+ (for GPU support)
- cmake (for native components)
- NVIDIA GPU with CC 5.0+ (for CUDA tests)

## ğŸ“‹ File Organization

**NEVER save to root!** Use proper directories:
- `/src` - Source code
- `/tests` - Test files
- `/docs` - Documentation
- `/benchmarks` - Performance tests
- `/scripts` - Utility scripts
- `/samples` - Example code

---

**Remember**: Quality first, no shortcuts, production-grade only!
